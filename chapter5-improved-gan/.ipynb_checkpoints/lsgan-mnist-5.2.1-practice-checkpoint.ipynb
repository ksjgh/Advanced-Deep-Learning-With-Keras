{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "'''Trains LSGAN on MNIST using Keras\n",
    "LSGAN is similar to DCGAN except for the MSE loss used by the \n",
    "Discriminator and Adversarial networks.\n",
    "  \n",
    "[1] Radford, Alec, Luke Metz, and Soumith Chintala.\n",
    "\"Unsupervised representation learning with deep convolutional\n",
    "generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015).\n",
    "[2] Mao, Xudong, et al. \"Least squares generative adversarial networks.\" \n",
    "2017 IEEE International Conference on Computer Vision (ICCV). IEEE, 2017.\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from lib import gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# reshape data for CNN as (28, 28, 1) and normalize\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lsgan_mnist-practice\"\n",
    "# network parameters\n",
    "# the latent or z vector is 100-dim\n",
    "latent_size = 100\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 64\n",
    "lr = 2e-4\n",
    "decay = 6e-8\n",
    "train_steps = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 1,080,577\n",
      "Trainable params: 1,080,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build discriminator model\n",
    "inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "discriminator = gan.discriminator(inputs, activation=None)\n",
    "# [1] uses Adam, but discriminator converges easily with RMSprop\n",
    "optimizer = RMSprop(lr=lr, decay=decay)\n",
    "\n",
    "# LSGAN uses MSE loss [2]\n",
    "discriminator.compile(loss='mse',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_input (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,301,505\n",
      "Trainable params: 1,300,801\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build generator model\n",
    "input_shape = (latent_size, )\n",
    "inputs = Input(shape=input_shape, name='z_input')\n",
    "generator = gan.generator(inputs, image_size)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_input (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 28, 28, 1)         1301505   \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 1080577   \n",
      "=================================================================\n",
      "Total params: 2,382,082\n",
      "Trainable params: 1,300,801\n",
      "Non-trainable params: 1,081,281\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build adversarial model = generator + discriminator\n",
    "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
    "    \n",
    "# freeze the weights of discriminator during adversarial training\n",
    "discriminator.trainable = False\n",
    "adversarial = Model(inputs,\n",
    "                    discriminator(generator(inputs)),\n",
    "                    name=model_name)\n",
    "\n",
    "# LSGAN uses MSE loss [2]\n",
    "adversarial.compile(loss='mse',\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=['accuracy'])\n",
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [discriminator loss: 0.489957, acc: 0.500000] [adversarial loss: 0.317937, acc: 0.000000]\n",
      "1: [discriminator loss: 0.436217, acc: 0.125000] [adversarial loss: 1.076837, acc: 0.000000]\n",
      "2: [discriminator loss: 0.318647, acc: 0.500000] [adversarial loss: 0.678014, acc: 0.000000]\n",
      "3: [discriminator loss: 0.195169, acc: 0.695312] [adversarial loss: 0.821097, acc: 0.000000]\n",
      "4: [discriminator loss: 0.096749, acc: 0.875000] [adversarial loss: 0.358316, acc: 0.000000]\n",
      "5: [discriminator loss: 0.111108, acc: 1.000000] [adversarial loss: 1.343064, acc: 0.000000]\n",
      "6: [discriminator loss: 0.135078, acc: 0.851562] [adversarial loss: 0.516648, acc: 0.000000]\n",
      "7: [discriminator loss: 0.137410, acc: 0.773438] [adversarial loss: 1.134449, acc: 0.000000]\n",
      "8: [discriminator loss: 0.125607, acc: 0.882812] [adversarial loss: 0.535258, acc: 0.000000]\n",
      "9: [discriminator loss: 0.039848, acc: 0.953125] [adversarial loss: 0.268256, acc: 0.312500]\n",
      "10: [discriminator loss: 0.017624, acc: 1.000000] [adversarial loss: 0.322177, acc: 0.062500]\n",
      "11: [discriminator loss: 0.018811, acc: 0.992188] [adversarial loss: 0.219512, acc: 0.796875]\n",
      "12: [discriminator loss: 0.021847, acc: 1.000000] [adversarial loss: 0.245215, acc: 0.609375]\n",
      "13: [discriminator loss: 0.016900, acc: 1.000000] [adversarial loss: 0.184344, acc: 0.921875]\n",
      "14: [discriminator loss: 0.018274, acc: 1.000000] [adversarial loss: 0.210584, acc: 0.796875]\n",
      "15: [discriminator loss: 0.016670, acc: 0.992188] [adversarial loss: 0.186631, acc: 0.906250]\n",
      "16: [discriminator loss: 0.016977, acc: 0.992188] [adversarial loss: 0.204513, acc: 0.843750]\n",
      "17: [discriminator loss: 0.012449, acc: 1.000000] [adversarial loss: 0.228528, acc: 0.687500]\n",
      "18: [discriminator loss: 0.015330, acc: 0.992188] [adversarial loss: 0.060683, acc: 1.000000]\n",
      "19: [discriminator loss: 0.038990, acc: 0.992188] [adversarial loss: 0.832235, acc: 0.000000]\n",
      "20: [discriminator loss: 0.103680, acc: 0.937500] [adversarial loss: 0.169697, acc: 0.968750]\n",
      "21: [discriminator loss: 0.012488, acc: 1.000000] [adversarial loss: 0.288532, acc: 0.265625]\n",
      "22: [discriminator loss: 0.011133, acc: 1.000000] [adversarial loss: 0.144097, acc: 1.000000]\n",
      "23: [discriminator loss: 0.013942, acc: 1.000000] [adversarial loss: 0.292702, acc: 0.187500]\n",
      "24: [discriminator loss: 0.016648, acc: 1.000000] [adversarial loss: 0.111589, acc: 1.000000]\n",
      "25: [discriminator loss: 0.016366, acc: 1.000000] [adversarial loss: 0.354675, acc: 0.000000]\n",
      "26: [discriminator loss: 0.026736, acc: 1.000000] [adversarial loss: 0.080949, acc: 1.000000]\n",
      "27: [discriminator loss: 0.023245, acc: 1.000000] [adversarial loss: 0.389442, acc: 0.000000]\n",
      "28: [discriminator loss: 0.032543, acc: 1.000000] [adversarial loss: 0.091293, acc: 1.000000]\n",
      "29: [discriminator loss: 0.017423, acc: 0.992188] [adversarial loss: 0.288345, acc: 0.093750]\n",
      "30: [discriminator loss: 0.016439, acc: 1.000000] [adversarial loss: 0.098377, acc: 1.000000]\n",
      "31: [discriminator loss: 0.012617, acc: 1.000000] [adversarial loss: 0.279800, acc: 0.218750]\n",
      "32: [discriminator loss: 0.012723, acc: 1.000000] [adversarial loss: 0.103967, acc: 1.000000]\n",
      "33: [discriminator loss: 0.011397, acc: 1.000000] [adversarial loss: 0.303364, acc: 0.078125]\n",
      "34: [discriminator loss: 0.017985, acc: 1.000000] [adversarial loss: 0.098378, acc: 1.000000]\n",
      "35: [discriminator loss: 0.015940, acc: 1.000000] [adversarial loss: 0.395711, acc: 0.000000]\n",
      "36: [discriminator loss: 0.034009, acc: 0.992188] [adversarial loss: 0.095208, acc: 1.000000]\n",
      "37: [discriminator loss: 0.024600, acc: 1.000000] [adversarial loss: 0.437510, acc: 0.000000]\n",
      "38: [discriminator loss: 0.038004, acc: 1.000000] [adversarial loss: 0.127945, acc: 1.000000]\n",
      "39: [discriminator loss: 0.018100, acc: 1.000000] [adversarial loss: 0.424726, acc: 0.000000]\n",
      "40: [discriminator loss: 0.025711, acc: 1.000000] [adversarial loss: 0.170765, acc: 1.000000]\n",
      "41: [discriminator loss: 0.015014, acc: 1.000000] [adversarial loss: 0.418438, acc: 0.000000]\n",
      "42: [discriminator loss: 0.017663, acc: 1.000000] [adversarial loss: 0.182097, acc: 1.000000]\n",
      "43: [discriminator loss: 0.016151, acc: 1.000000] [adversarial loss: 0.448742, acc: 0.000000]\n",
      "44: [discriminator loss: 0.027919, acc: 1.000000] [adversarial loss: 0.133267, acc: 1.000000]\n",
      "45: [discriminator loss: 0.031565, acc: 1.000000] [adversarial loss: 0.564064, acc: 0.000000]\n",
      "46: [discriminator loss: 0.055268, acc: 1.000000] [adversarial loss: 0.031028, acc: 1.000000]\n",
      "47: [discriminator loss: 0.058163, acc: 0.984375] [adversarial loss: 0.598506, acc: 0.000000]\n",
      "48: [discriminator loss: 0.063280, acc: 0.984375] [adversarial loss: 0.104035, acc: 1.000000]\n",
      "49: [discriminator loss: 0.016949, acc: 1.000000] [adversarial loss: 0.317535, acc: 0.203125]\n",
      "50: [discriminator loss: 0.014711, acc: 1.000000] [adversarial loss: 0.103604, acc: 0.937500]\n",
      "51: [discriminator loss: 0.063886, acc: 0.953125] [adversarial loss: 1.001510, acc: 0.000000]\n",
      "52: [discriminator loss: 0.084335, acc: 0.953125] [adversarial loss: 0.307204, acc: 0.046875]\n",
      "53: [discriminator loss: 0.027687, acc: 1.000000] [adversarial loss: 0.563218, acc: 0.000000]\n",
      "54: [discriminator loss: 0.021464, acc: 1.000000] [adversarial loss: 0.173741, acc: 0.953125]\n",
      "55: [discriminator loss: 0.033940, acc: 0.992188] [adversarial loss: 0.625953, acc: 0.000000]\n",
      "56: [discriminator loss: 0.049480, acc: 0.992188] [adversarial loss: 0.164183, acc: 0.984375]\n",
      "57: [discriminator loss: 0.028250, acc: 0.992188] [adversarial loss: 0.451843, acc: 0.000000]\n",
      "58: [discriminator loss: 0.026478, acc: 1.000000] [adversarial loss: 0.098858, acc: 1.000000]\n",
      "59: [discriminator loss: 0.045918, acc: 0.984375] [adversarial loss: 0.484137, acc: 0.000000]\n",
      "60: [discriminator loss: 0.048165, acc: 1.000000] [adversarial loss: 0.411268, acc: 0.031250]\n",
      "61: [discriminator loss: 0.105184, acc: 0.843750] [adversarial loss: 1.145085, acc: 0.000000]\n",
      "62: [discriminator loss: 0.092483, acc: 0.914062] [adversarial loss: 0.527395, acc: 0.000000]\n",
      "63: [discriminator loss: 0.026067, acc: 0.992188] [adversarial loss: 0.466734, acc: 0.000000]\n",
      "64: [discriminator loss: 0.020984, acc: 0.992188] [adversarial loss: 0.422305, acc: 0.000000]\n",
      "65: [discriminator loss: 0.014879, acc: 1.000000] [adversarial loss: 0.479962, acc: 0.000000]\n",
      "66: [discriminator loss: 0.015019, acc: 0.992188] [adversarial loss: 0.404117, acc: 0.000000]\n",
      "67: [discriminator loss: 0.034038, acc: 0.984375] [adversarial loss: 0.791123, acc: 0.000000]\n",
      "68: [discriminator loss: 0.041514, acc: 0.976562] [adversarial loss: 0.317691, acc: 0.000000]\n",
      "69: [discriminator loss: 0.065205, acc: 0.992188] [adversarial loss: 0.798121, acc: 0.000000]\n",
      "70: [discriminator loss: 0.085040, acc: 0.945312] [adversarial loss: 0.362612, acc: 0.000000]\n",
      "71: [discriminator loss: 0.021550, acc: 1.000000] [adversarial loss: 0.415913, acc: 0.000000]\n",
      "72: [discriminator loss: 0.021506, acc: 1.000000] [adversarial loss: 0.304959, acc: 0.015625]\n",
      "73: [discriminator loss: 0.017681, acc: 1.000000] [adversarial loss: 0.426420, acc: 0.000000]\n",
      "74: [discriminator loss: 0.022006, acc: 0.984375] [adversarial loss: 0.192142, acc: 0.921875]\n",
      "75: [discriminator loss: 0.027211, acc: 1.000000] [adversarial loss: 0.591974, acc: 0.000000]\n",
      "76: [discriminator loss: 0.035823, acc: 0.984375] [adversarial loss: 0.217453, acc: 0.875000]\n",
      "77: [discriminator loss: 0.028254, acc: 1.000000] [adversarial loss: 0.588656, acc: 0.000000]\n",
      "78: [discriminator loss: 0.035742, acc: 0.992188] [adversarial loss: 0.260949, acc: 0.437500]\n",
      "79: [discriminator loss: 0.035806, acc: 0.992188] [adversarial loss: 0.684889, acc: 0.000000]\n",
      "80: [discriminator loss: 0.039189, acc: 0.984375] [adversarial loss: 0.372775, acc: 0.000000]\n",
      "81: [discriminator loss: 0.064010, acc: 0.976562] [adversarial loss: 0.830266, acc: 0.000000]\n",
      "82: [discriminator loss: 0.077762, acc: 0.929688] [adversarial loss: 0.298504, acc: 0.171875]\n",
      "83: [discriminator loss: 0.260870, acc: 0.531250] [adversarial loss: 0.959171, acc: 0.000000]\n",
      "84: [discriminator loss: 0.166544, acc: 0.664062] [adversarial loss: 0.524167, acc: 0.000000]\n",
      "85: [discriminator loss: 0.122167, acc: 0.882812] [adversarial loss: 0.661756, acc: 0.000000]\n",
      "86: [discriminator loss: 0.069982, acc: 0.945312] [adversarial loss: 0.605677, acc: 0.000000]\n",
      "87: [discriminator loss: 0.056099, acc: 0.984375] [adversarial loss: 0.680350, acc: 0.000000]\n",
      "88: [discriminator loss: 0.049222, acc: 1.000000] [adversarial loss: 0.758577, acc: 0.000000]\n",
      "89: [discriminator loss: 0.044505, acc: 0.992188] [adversarial loss: 0.725793, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90: [discriminator loss: 0.091125, acc: 0.968750] [adversarial loss: 0.879844, acc: 0.000000]\n",
      "91: [discriminator loss: 0.214578, acc: 0.640625] [adversarial loss: 0.884336, acc: 0.000000]\n",
      "92: [discriminator loss: 0.180697, acc: 0.835938] [adversarial loss: 0.888554, acc: 0.000000]\n",
      "93: [discriminator loss: 0.058803, acc: 0.992188] [adversarial loss: 0.770708, acc: 0.000000]\n",
      "94: [discriminator loss: 0.176875, acc: 0.562500] [adversarial loss: 1.095531, acc: 0.000000]\n",
      "95: [discriminator loss: 0.230976, acc: 0.632812] [adversarial loss: 0.635315, acc: 0.000000]\n",
      "96: [discriminator loss: 0.307816, acc: 0.437500] [adversarial loss: 0.957311, acc: 0.000000]\n",
      "97: [discriminator loss: 0.205905, acc: 0.562500] [adversarial loss: 0.580236, acc: 0.000000]\n",
      "98: [discriminator loss: 0.118245, acc: 0.968750] [adversarial loss: 0.758137, acc: 0.000000]\n",
      "99: [discriminator loss: 0.069871, acc: 0.968750] [adversarial loss: 0.651935, acc: 0.000000]\n",
      "100: [discriminator loss: 0.059583, acc: 1.000000] [adversarial loss: 0.813932, acc: 0.000000]\n",
      "101: [discriminator loss: 0.069631, acc: 0.960938] [adversarial loss: 0.686149, acc: 0.000000]\n",
      "102: [discriminator loss: 0.102080, acc: 0.945312] [adversarial loss: 0.997292, acc: 0.000000]\n",
      "103: [discriminator loss: 0.095216, acc: 0.914062] [adversarial loss: 0.751692, acc: 0.000000]\n",
      "104: [discriminator loss: 0.106831, acc: 0.968750] [adversarial loss: 1.082527, acc: 0.000000]\n",
      "105: [discriminator loss: 0.093428, acc: 0.921875] [adversarial loss: 0.849327, acc: 0.000000]\n",
      "106: [discriminator loss: 0.092983, acc: 0.992188] [adversarial loss: 1.059693, acc: 0.000000]\n",
      "107: [discriminator loss: 0.122528, acc: 0.851562] [adversarial loss: 0.763350, acc: 0.000000]\n",
      "108: [discriminator loss: 0.158098, acc: 0.687500] [adversarial loss: 1.019660, acc: 0.000000]\n",
      "109: [discriminator loss: 0.140413, acc: 0.796875] [adversarial loss: 0.716174, acc: 0.000000]\n",
      "110: [discriminator loss: 0.185942, acc: 0.531250] [adversarial loss: 1.058253, acc: 0.000000]\n",
      "111: [discriminator loss: 0.140024, acc: 0.773438] [adversarial loss: 0.814391, acc: 0.000000]\n",
      "112: [discriminator loss: 0.078059, acc: 1.000000] [adversarial loss: 0.926282, acc: 0.000000]\n",
      "113: [discriminator loss: 0.048921, acc: 1.000000] [adversarial loss: 0.864730, acc: 0.000000]\n",
      "114: [discriminator loss: 0.052948, acc: 0.992188] [adversarial loss: 0.905594, acc: 0.000000]\n",
      "115: [discriminator loss: 0.050582, acc: 0.984375] [adversarial loss: 0.782605, acc: 0.000000]\n",
      "116: [discriminator loss: 0.085235, acc: 1.000000] [adversarial loss: 0.906941, acc: 0.000000]\n",
      "117: [discriminator loss: 0.103544, acc: 0.929688] [adversarial loss: 0.627332, acc: 0.000000]\n",
      "118: [discriminator loss: 0.176840, acc: 0.507812] [adversarial loss: 1.041117, acc: 0.000000]\n",
      "119: [discriminator loss: 0.136474, acc: 0.773438] [adversarial loss: 0.560081, acc: 0.000000]\n",
      "120: [discriminator loss: 0.127541, acc: 0.851562] [adversarial loss: 1.101312, acc: 0.000000]\n",
      "121: [discriminator loss: 0.149523, acc: 0.718750] [adversarial loss: 0.627211, acc: 0.000000]\n",
      "122: [discriminator loss: 0.091120, acc: 0.984375] [adversarial loss: 1.038216, acc: 0.000000]\n",
      "123: [discriminator loss: 0.061216, acc: 0.984375] [adversarial loss: 0.761094, acc: 0.000000]\n",
      "124: [discriminator loss: 0.066741, acc: 0.984375] [adversarial loss: 1.036107, acc: 0.000000]\n",
      "125: [discriminator loss: 0.058997, acc: 0.976562] [adversarial loss: 0.758807, acc: 0.000000]\n",
      "126: [discriminator loss: 0.142937, acc: 0.757812] [adversarial loss: 1.119152, acc: 0.000000]\n",
      "127: [discriminator loss: 0.149811, acc: 0.695312] [adversarial loss: 0.629990, acc: 0.000000]\n",
      "128: [discriminator loss: 0.119031, acc: 0.945312] [adversarial loss: 1.039379, acc: 0.000000]\n",
      "129: [discriminator loss: 0.069526, acc: 0.921875] [adversarial loss: 0.755348, acc: 0.000000]\n",
      "130: [discriminator loss: 0.084938, acc: 1.000000] [adversarial loss: 0.973477, acc: 0.000000]\n",
      "131: [discriminator loss: 0.084245, acc: 0.937500] [adversarial loss: 0.619276, acc: 0.000000]\n",
      "132: [discriminator loss: 0.100484, acc: 0.992188] [adversarial loss: 0.945708, acc: 0.000000]\n",
      "133: [discriminator loss: 0.073387, acc: 0.953125] [adversarial loss: 0.686514, acc: 0.000000]\n",
      "134: [discriminator loss: 0.072909, acc: 1.000000] [adversarial loss: 1.014364, acc: 0.000000]\n",
      "135: [discriminator loss: 0.075670, acc: 0.929688] [adversarial loss: 0.658011, acc: 0.000000]\n",
      "136: [discriminator loss: 0.084642, acc: 0.992188] [adversarial loss: 1.069536, acc: 0.000000]\n",
      "137: [discriminator loss: 0.105358, acc: 0.828125] [adversarial loss: 0.637772, acc: 0.000000]\n",
      "138: [discriminator loss: 0.093210, acc: 0.960938] [adversarial loss: 0.943659, acc: 0.000000]\n",
      "139: [discriminator loss: 0.084385, acc: 0.898438] [adversarial loss: 0.676195, acc: 0.000000]\n",
      "140: [discriminator loss: 0.082480, acc: 0.960938] [adversarial loss: 0.864227, acc: 0.000000]\n",
      "141: [discriminator loss: 0.072667, acc: 0.945312] [adversarial loss: 0.689570, acc: 0.000000]\n",
      "142: [discriminator loss: 0.095627, acc: 0.929688] [adversarial loss: 0.788458, acc: 0.000000]\n",
      "143: [discriminator loss: 0.106116, acc: 0.890625] [adversarial loss: 0.557558, acc: 0.015625]\n",
      "144: [discriminator loss: 0.091779, acc: 0.960938] [adversarial loss: 0.887327, acc: 0.000000]\n",
      "145: [discriminator loss: 0.103796, acc: 0.843750] [adversarial loss: 0.526617, acc: 0.000000]\n",
      "146: [discriminator loss: 0.107941, acc: 0.890625] [adversarial loss: 0.809998, acc: 0.000000]\n",
      "147: [discriminator loss: 0.087926, acc: 0.906250] [adversarial loss: 0.486009, acc: 0.015625]\n",
      "148: [discriminator loss: 0.080617, acc: 0.960938] [adversarial loss: 0.753582, acc: 0.000000]\n",
      "149: [discriminator loss: 0.097174, acc: 0.882812] [adversarial loss: 0.509411, acc: 0.031250]\n",
      "150: [discriminator loss: 0.084712, acc: 0.921875] [adversarial loss: 0.706285, acc: 0.000000]\n",
      "151: [discriminator loss: 0.083875, acc: 0.929688] [adversarial loss: 0.400135, acc: 0.218750]\n",
      "152: [discriminator loss: 0.076927, acc: 0.992188] [adversarial loss: 0.830414, acc: 0.000000]\n",
      "153: [discriminator loss: 0.113547, acc: 0.851562] [adversarial loss: 0.384106, acc: 0.187500]\n",
      "154: [discriminator loss: 0.118993, acc: 0.890625] [adversarial loss: 0.866804, acc: 0.000000]\n",
      "155: [discriminator loss: 0.107813, acc: 0.867188] [adversarial loss: 0.446450, acc: 0.140625]\n",
      "156: [discriminator loss: 0.084874, acc: 0.898438] [adversarial loss: 0.723897, acc: 0.015625]\n",
      "157: [discriminator loss: 0.096723, acc: 0.867188] [adversarial loss: 0.449378, acc: 0.093750]\n",
      "158: [discriminator loss: 0.089714, acc: 0.929688] [adversarial loss: 0.806663, acc: 0.015625]\n",
      "159: [discriminator loss: 0.099875, acc: 0.851562] [adversarial loss: 0.339523, acc: 0.328125]\n",
      "160: [discriminator loss: 0.112814, acc: 0.898438] [adversarial loss: 0.894770, acc: 0.000000]\n",
      "161: [discriminator loss: 0.110145, acc: 0.867188] [adversarial loss: 0.488954, acc: 0.125000]\n",
      "162: [discriminator loss: 0.076561, acc: 0.937500] [adversarial loss: 0.581336, acc: 0.046875]\n",
      "163: [discriminator loss: 0.063145, acc: 0.976562] [adversarial loss: 0.563777, acc: 0.062500]\n",
      "164: [discriminator loss: 0.078705, acc: 0.945312] [adversarial loss: 0.615823, acc: 0.062500]\n",
      "165: [discriminator loss: 0.074129, acc: 0.945312] [adversarial loss: 0.460981, acc: 0.093750]\n",
      "166: [discriminator loss: 0.081669, acc: 0.906250] [adversarial loss: 0.728232, acc: 0.000000]\n",
      "167: [discriminator loss: 0.091480, acc: 0.898438] [adversarial loss: 0.278721, acc: 0.468750]\n",
      "168: [discriminator loss: 0.132454, acc: 0.851562] [adversarial loss: 0.931276, acc: 0.000000]\n",
      "169: [discriminator loss: 0.169989, acc: 0.656250] [adversarial loss: 0.371720, acc: 0.234375]\n",
      "170: [discriminator loss: 0.087064, acc: 0.929688] [adversarial loss: 0.537438, acc: 0.046875]\n",
      "171: [discriminator loss: 0.077744, acc: 0.945312] [adversarial loss: 0.466325, acc: 0.062500]\n",
      "172: [discriminator loss: 0.070531, acc: 0.968750] [adversarial loss: 0.487531, acc: 0.109375]\n",
      "173: [discriminator loss: 0.062836, acc: 0.984375] [adversarial loss: 0.420921, acc: 0.140625]\n",
      "174: [discriminator loss: 0.055862, acc: 0.976562] [adversarial loss: 0.533106, acc: 0.046875]\n",
      "175: [discriminator loss: 0.076611, acc: 0.953125] [adversarial loss: 0.274576, acc: 0.515625]\n",
      "176: [discriminator loss: 0.080254, acc: 0.898438] [adversarial loss: 0.663382, acc: 0.015625]\n",
      "177: [discriminator loss: 0.093823, acc: 0.890625] [adversarial loss: 0.291789, acc: 0.437500]\n",
      "178: [discriminator loss: 0.080372, acc: 0.906250] [adversarial loss: 0.563595, acc: 0.031250]\n",
      "179: [discriminator loss: 0.103336, acc: 0.882812] [adversarial loss: 0.216063, acc: 0.640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180: [discriminator loss: 0.110716, acc: 0.859375] [adversarial loss: 0.688729, acc: 0.015625]\n",
      "181: [discriminator loss: 0.132075, acc: 0.804688] [adversarial loss: 0.254264, acc: 0.562500]\n",
      "182: [discriminator loss: 0.099647, acc: 0.867188] [adversarial loss: 0.576523, acc: 0.000000]\n",
      "183: [discriminator loss: 0.082081, acc: 0.953125] [adversarial loss: 0.337571, acc: 0.281250]\n",
      "184: [discriminator loss: 0.065468, acc: 0.953125] [adversarial loss: 0.494785, acc: 0.031250]\n",
      "185: [discriminator loss: 0.060280, acc: 0.992188] [adversarial loss: 0.305608, acc: 0.390625]\n",
      "186: [discriminator loss: 0.069161, acc: 0.945312] [adversarial loss: 0.506564, acc: 0.046875]\n",
      "187: [discriminator loss: 0.076425, acc: 0.953125] [adversarial loss: 0.246932, acc: 0.515625]\n",
      "188: [discriminator loss: 0.090472, acc: 0.882812] [adversarial loss: 0.540150, acc: 0.031250]\n",
      "189: [discriminator loss: 0.093870, acc: 0.921875] [adversarial loss: 0.178733, acc: 0.750000]\n",
      "190: [discriminator loss: 0.082771, acc: 0.945312] [adversarial loss: 0.514266, acc: 0.031250]\n",
      "191: [discriminator loss: 0.092343, acc: 0.906250] [adversarial loss: 0.176535, acc: 0.703125]\n",
      "192: [discriminator loss: 0.097312, acc: 0.867188] [adversarial loss: 0.426726, acc: 0.062500]\n",
      "193: [discriminator loss: 0.077473, acc: 0.945312] [adversarial loss: 0.199422, acc: 0.671875]\n",
      "194: [discriminator loss: 0.087998, acc: 0.914062] [adversarial loss: 0.436699, acc: 0.046875]\n",
      "195: [discriminator loss: 0.076417, acc: 0.945312] [adversarial loss: 0.179918, acc: 0.781250]\n",
      "196: [discriminator loss: 0.053790, acc: 0.968750] [adversarial loss: 0.382165, acc: 0.125000]\n",
      "197: [discriminator loss: 0.071400, acc: 0.953125] [adversarial loss: 0.158338, acc: 0.875000]\n",
      "198: [discriminator loss: 0.070054, acc: 0.945312] [adversarial loss: 0.377297, acc: 0.125000]\n",
      "199: [discriminator loss: 0.092773, acc: 0.914062] [adversarial loss: 0.129668, acc: 0.937500]\n",
      "200: [discriminator loss: 0.101217, acc: 0.875000] [adversarial loss: 0.563608, acc: 0.000000]\n",
      "201: [discriminator loss: 0.129527, acc: 0.796875] [adversarial loss: 0.163545, acc: 0.828125]\n",
      "202: [discriminator loss: 0.089653, acc: 0.914062] [adversarial loss: 0.489555, acc: 0.031250]\n",
      "203: [discriminator loss: 0.112998, acc: 0.867188] [adversarial loss: 0.190559, acc: 0.718750]\n",
      "204: [discriminator loss: 0.097578, acc: 0.875000] [adversarial loss: 0.470468, acc: 0.015625]\n",
      "205: [discriminator loss: 0.107191, acc: 0.898438] [adversarial loss: 0.157766, acc: 0.843750]\n",
      "206: [discriminator loss: 0.080448, acc: 0.929688] [adversarial loss: 0.402049, acc: 0.093750]\n",
      "207: [discriminator loss: 0.087522, acc: 0.953125] [adversarial loss: 0.243904, acc: 0.593750]\n",
      "208: [discriminator loss: 0.072426, acc: 0.929688] [adversarial loss: 0.454544, acc: 0.031250]\n",
      "209: [discriminator loss: 0.081392, acc: 0.960938] [adversarial loss: 0.226859, acc: 0.625000]\n",
      "210: [discriminator loss: 0.096373, acc: 0.890625] [adversarial loss: 0.502302, acc: 0.000000]\n",
      "211: [discriminator loss: 0.126530, acc: 0.820312] [adversarial loss: 0.147850, acc: 0.921875]\n",
      "212: [discriminator loss: 0.115335, acc: 0.820312] [adversarial loss: 0.501816, acc: 0.000000]\n",
      "213: [discriminator loss: 0.115297, acc: 0.882812] [adversarial loss: 0.191632, acc: 0.781250]\n",
      "214: [discriminator loss: 0.119230, acc: 0.828125] [adversarial loss: 0.520044, acc: 0.000000]\n",
      "215: [discriminator loss: 0.126020, acc: 0.875000] [adversarial loss: 0.188482, acc: 0.765625]\n",
      "216: [discriminator loss: 0.098033, acc: 0.882812] [adversarial loss: 0.495698, acc: 0.015625]\n",
      "217: [discriminator loss: 0.099314, acc: 0.929688] [adversarial loss: 0.206063, acc: 0.703125]\n",
      "218: [discriminator loss: 0.092441, acc: 0.906250] [adversarial loss: 0.392914, acc: 0.140625]\n",
      "219: [discriminator loss: 0.095723, acc: 0.960938] [adversarial loss: 0.168712, acc: 0.859375]\n",
      "220: [discriminator loss: 0.112715, acc: 0.859375] [adversarial loss: 0.437176, acc: 0.046875]\n",
      "221: [discriminator loss: 0.109874, acc: 0.914062] [adversarial loss: 0.242378, acc: 0.515625]\n",
      "222: [discriminator loss: 0.107071, acc: 0.859375] [adversarial loss: 0.601565, acc: 0.000000]\n",
      "223: [discriminator loss: 0.131012, acc: 0.820312] [adversarial loss: 0.213867, acc: 0.718750]\n",
      "224: [discriminator loss: 0.130379, acc: 0.765625] [adversarial loss: 0.769217, acc: 0.000000]\n",
      "225: [discriminator loss: 0.174076, acc: 0.695312] [adversarial loss: 0.246265, acc: 0.546875]\n",
      "226: [discriminator loss: 0.145099, acc: 0.804688] [adversarial loss: 0.494057, acc: 0.000000]\n",
      "227: [discriminator loss: 0.150518, acc: 0.820312] [adversarial loss: 0.182974, acc: 0.828125]\n",
      "228: [discriminator loss: 0.137374, acc: 0.789062] [adversarial loss: 0.426228, acc: 0.015625]\n",
      "229: [discriminator loss: 0.128002, acc: 0.882812] [adversarial loss: 0.276966, acc: 0.390625]\n",
      "230: [discriminator loss: 0.133836, acc: 0.804688] [adversarial loss: 0.512715, acc: 0.015625]\n",
      "231: [discriminator loss: 0.136073, acc: 0.890625] [adversarial loss: 0.365399, acc: 0.125000]\n",
      "232: [discriminator loss: 0.124038, acc: 0.828125] [adversarial loss: 0.767937, acc: 0.000000]\n",
      "233: [discriminator loss: 0.179256, acc: 0.695312] [adversarial loss: 0.206195, acc: 0.671875]\n",
      "234: [discriminator loss: 0.145394, acc: 0.773438] [adversarial loss: 0.559146, acc: 0.000000]\n",
      "235: [discriminator loss: 0.158903, acc: 0.796875] [adversarial loss: 0.222639, acc: 0.640625]\n",
      "236: [discriminator loss: 0.153984, acc: 0.773438] [adversarial loss: 0.452147, acc: 0.031250]\n",
      "237: [discriminator loss: 0.139750, acc: 0.820312] [adversarial loss: 0.207170, acc: 0.718750]\n",
      "238: [discriminator loss: 0.163653, acc: 0.750000] [adversarial loss: 0.768983, acc: 0.000000]\n",
      "239: [discriminator loss: 0.143304, acc: 0.789062] [adversarial loss: 0.316430, acc: 0.250000]\n",
      "240: [discriminator loss: 0.145680, acc: 0.765625] [adversarial loss: 0.731744, acc: 0.000000]\n",
      "241: [discriminator loss: 0.163030, acc: 0.718750] [adversarial loss: 0.291348, acc: 0.390625]\n",
      "242: [discriminator loss: 0.123403, acc: 0.843750] [adversarial loss: 0.348236, acc: 0.187500]\n",
      "243: [discriminator loss: 0.125352, acc: 0.867188] [adversarial loss: 0.339888, acc: 0.328125]\n",
      "244: [discriminator loss: 0.145930, acc: 0.835938] [adversarial loss: 0.292629, acc: 0.359375]\n",
      "245: [discriminator loss: 0.143059, acc: 0.843750] [adversarial loss: 0.444105, acc: 0.062500]\n",
      "246: [discriminator loss: 0.131395, acc: 0.882812] [adversarial loss: 0.405192, acc: 0.125000]\n",
      "247: [discriminator loss: 0.141959, acc: 0.820312] [adversarial loss: 0.597742, acc: 0.000000]\n",
      "248: [discriminator loss: 0.140149, acc: 0.835938] [adversarial loss: 0.246896, acc: 0.484375]\n",
      "249: [discriminator loss: 0.170318, acc: 0.750000] [adversarial loss: 0.637114, acc: 0.000000]\n",
      "250: [discriminator loss: 0.190489, acc: 0.640625] [adversarial loss: 0.161142, acc: 0.875000]\n",
      "251: [discriminator loss: 0.166871, acc: 0.687500] [adversarial loss: 0.560689, acc: 0.015625]\n",
      "252: [discriminator loss: 0.182544, acc: 0.703125] [adversarial loss: 0.270124, acc: 0.406250]\n",
      "253: [discriminator loss: 0.153748, acc: 0.742188] [adversarial loss: 0.538442, acc: 0.015625]\n",
      "254: [discriminator loss: 0.154631, acc: 0.789062] [adversarial loss: 0.307825, acc: 0.312500]\n",
      "255: [discriminator loss: 0.121174, acc: 0.882812] [adversarial loss: 0.481628, acc: 0.015625]\n",
      "256: [discriminator loss: 0.150457, acc: 0.781250] [adversarial loss: 0.373211, acc: 0.093750]\n",
      "257: [discriminator loss: 0.136074, acc: 0.851562] [adversarial loss: 0.523507, acc: 0.031250]\n",
      "258: [discriminator loss: 0.165793, acc: 0.765625] [adversarial loss: 0.205320, acc: 0.703125]\n",
      "259: [discriminator loss: 0.201678, acc: 0.718750] [adversarial loss: 0.652327, acc: 0.015625]\n",
      "260: [discriminator loss: 0.213845, acc: 0.578125] [adversarial loss: 0.133522, acc: 0.937500]\n",
      "261: [discriminator loss: 0.181056, acc: 0.703125] [adversarial loss: 0.486087, acc: 0.015625]\n",
      "262: [discriminator loss: 0.157684, acc: 0.765625] [adversarial loss: 0.236138, acc: 0.609375]\n",
      "263: [discriminator loss: 0.148951, acc: 0.789062] [adversarial loss: 0.499261, acc: 0.015625]\n",
      "264: [discriminator loss: 0.143956, acc: 0.804688] [adversarial loss: 0.314458, acc: 0.312500]\n",
      "265: [discriminator loss: 0.140964, acc: 0.789062] [adversarial loss: 0.397949, acc: 0.125000]\n",
      "266: [discriminator loss: 0.148493, acc: 0.796875] [adversarial loss: 0.140080, acc: 0.875000]\n",
      "267: [discriminator loss: 0.151681, acc: 0.765625] [adversarial loss: 0.463119, acc: 0.031250]\n",
      "268: [discriminator loss: 0.175450, acc: 0.734375] [adversarial loss: 0.218953, acc: 0.656250]\n",
      "269: [discriminator loss: 0.168198, acc: 0.710938] [adversarial loss: 0.515910, acc: 0.000000]\n",
      "270: [discriminator loss: 0.179610, acc: 0.718750] [adversarial loss: 0.139584, acc: 0.968750]\n",
      "271: [discriminator loss: 0.167235, acc: 0.734375] [adversarial loss: 0.503260, acc: 0.031250]\n",
      "272: [discriminator loss: 0.155389, acc: 0.789062] [adversarial loss: 0.252243, acc: 0.484375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273: [discriminator loss: 0.150043, acc: 0.789062] [adversarial loss: 0.335010, acc: 0.234375]\n",
      "274: [discriminator loss: 0.162140, acc: 0.812500] [adversarial loss: 0.335670, acc: 0.250000]\n",
      "275: [discriminator loss: 0.144887, acc: 0.796875] [adversarial loss: 0.450315, acc: 0.078125]\n",
      "276: [discriminator loss: 0.144121, acc: 0.835938] [adversarial loss: 0.228143, acc: 0.578125]\n",
      "277: [discriminator loss: 0.138856, acc: 0.843750] [adversarial loss: 0.411463, acc: 0.140625]\n",
      "278: [discriminator loss: 0.178571, acc: 0.773438] [adversarial loss: 0.152504, acc: 0.890625]\n",
      "279: [discriminator loss: 0.154910, acc: 0.710938] [adversarial loss: 0.691714, acc: 0.000000]\n",
      "280: [discriminator loss: 0.185720, acc: 0.671875] [adversarial loss: 0.251373, acc: 0.515625]\n",
      "281: [discriminator loss: 0.162478, acc: 0.757812] [adversarial loss: 0.589974, acc: 0.015625]\n",
      "282: [discriminator loss: 0.176416, acc: 0.703125] [adversarial loss: 0.171542, acc: 0.796875]\n",
      "283: [discriminator loss: 0.148451, acc: 0.820312] [adversarial loss: 0.578517, acc: 0.000000]\n",
      "284: [discriminator loss: 0.167332, acc: 0.710938] [adversarial loss: 0.247158, acc: 0.593750]\n",
      "285: [discriminator loss: 0.168100, acc: 0.710938] [adversarial loss: 0.649701, acc: 0.000000]\n",
      "286: [discriminator loss: 0.179683, acc: 0.703125] [adversarial loss: 0.255897, acc: 0.546875]\n",
      "287: [discriminator loss: 0.191112, acc: 0.687500] [adversarial loss: 0.652565, acc: 0.000000]\n",
      "288: [discriminator loss: 0.188709, acc: 0.640625] [adversarial loss: 0.397294, acc: 0.093750]\n",
      "289: [discriminator loss: 0.149541, acc: 0.796875] [adversarial loss: 0.520539, acc: 0.015625]\n",
      "290: [discriminator loss: 0.163942, acc: 0.750000] [adversarial loss: 0.416814, acc: 0.093750]\n",
      "291: [discriminator loss: 0.131545, acc: 0.828125] [adversarial loss: 0.328572, acc: 0.281250]\n",
      "292: [discriminator loss: 0.141524, acc: 0.796875] [adversarial loss: 0.374402, acc: 0.093750]\n",
      "293: [discriminator loss: 0.176103, acc: 0.789062] [adversarial loss: 0.307653, acc: 0.343750]\n",
      "294: [discriminator loss: 0.173975, acc: 0.726562] [adversarial loss: 0.607466, acc: 0.000000]\n",
      "295: [discriminator loss: 0.162379, acc: 0.765625] [adversarial loss: 0.280222, acc: 0.421875]\n",
      "296: [discriminator loss: 0.175354, acc: 0.710938] [adversarial loss: 0.740462, acc: 0.000000]\n",
      "297: [discriminator loss: 0.231597, acc: 0.609375] [adversarial loss: 0.182249, acc: 0.812500]\n",
      "298: [discriminator loss: 0.185258, acc: 0.671875] [adversarial loss: 0.557750, acc: 0.000000]\n",
      "299: [discriminator loss: 0.173961, acc: 0.710938] [adversarial loss: 0.289139, acc: 0.375000]\n",
      "300: [discriminator loss: 0.148000, acc: 0.882812] [adversarial loss: 0.600039, acc: 0.000000]\n",
      "301: [discriminator loss: 0.143489, acc: 0.820312] [adversarial loss: 0.381312, acc: 0.156250]\n",
      "302: [discriminator loss: 0.152631, acc: 0.820312] [adversarial loss: 0.485589, acc: 0.000000]\n",
      "303: [discriminator loss: 0.166325, acc: 0.726562] [adversarial loss: 0.251691, acc: 0.515625]\n",
      "304: [discriminator loss: 0.173879, acc: 0.726562] [adversarial loss: 0.498615, acc: 0.015625]\n",
      "305: [discriminator loss: 0.155783, acc: 0.789062] [adversarial loss: 0.321291, acc: 0.265625]\n",
      "306: [discriminator loss: 0.171525, acc: 0.750000] [adversarial loss: 0.701898, acc: 0.000000]\n",
      "307: [discriminator loss: 0.182043, acc: 0.703125] [adversarial loss: 0.195112, acc: 0.796875]\n",
      "308: [discriminator loss: 0.192580, acc: 0.671875] [adversarial loss: 0.890756, acc: 0.000000]\n",
      "309: [discriminator loss: 0.226629, acc: 0.609375] [adversarial loss: 0.363431, acc: 0.109375]\n",
      "310: [discriminator loss: 0.168409, acc: 0.742188] [adversarial loss: 0.600157, acc: 0.000000]\n",
      "311: [discriminator loss: 0.163704, acc: 0.750000] [adversarial loss: 0.377829, acc: 0.125000]\n",
      "312: [discriminator loss: 0.166312, acc: 0.765625] [adversarial loss: 0.423893, acc: 0.062500]\n",
      "313: [discriminator loss: 0.159132, acc: 0.781250] [adversarial loss: 0.305026, acc: 0.328125]\n",
      "314: [discriminator loss: 0.144746, acc: 0.859375] [adversarial loss: 0.411099, acc: 0.046875]\n",
      "315: [discriminator loss: 0.162158, acc: 0.765625] [adversarial loss: 0.442915, acc: 0.031250]\n",
      "316: [discriminator loss: 0.146385, acc: 0.843750] [adversarial loss: 0.389571, acc: 0.078125]\n",
      "317: [discriminator loss: 0.171303, acc: 0.757812] [adversarial loss: 0.551031, acc: 0.000000]\n",
      "318: [discriminator loss: 0.165849, acc: 0.765625] [adversarial loss: 0.283755, acc: 0.421875]\n",
      "319: [discriminator loss: 0.178017, acc: 0.695312] [adversarial loss: 0.748040, acc: 0.000000]\n",
      "320: [discriminator loss: 0.196100, acc: 0.656250] [adversarial loss: 0.196809, acc: 0.718750]\n",
      "321: [discriminator loss: 0.176448, acc: 0.726562] [adversarial loss: 0.767698, acc: 0.000000]\n",
      "322: [discriminator loss: 0.190703, acc: 0.664062] [adversarial loss: 0.271182, acc: 0.437500]\n",
      "323: [discriminator loss: 0.198123, acc: 0.671875] [adversarial loss: 0.626343, acc: 0.000000]\n",
      "324: [discriminator loss: 0.158983, acc: 0.789062] [adversarial loss: 0.395612, acc: 0.062500]\n",
      "325: [discriminator loss: 0.158962, acc: 0.781250] [adversarial loss: 0.509489, acc: 0.000000]\n",
      "326: [discriminator loss: 0.149214, acc: 0.828125] [adversarial loss: 0.485917, acc: 0.046875]\n",
      "327: [discriminator loss: 0.159437, acc: 0.742188] [adversarial loss: 0.536037, acc: 0.000000]\n",
      "328: [discriminator loss: 0.143884, acc: 0.796875] [adversarial loss: 0.265184, acc: 0.500000]\n",
      "329: [discriminator loss: 0.147867, acc: 0.781250] [adversarial loss: 0.481835, acc: 0.031250]\n",
      "330: [discriminator loss: 0.150831, acc: 0.812500] [adversarial loss: 0.286547, acc: 0.437500]\n",
      "331: [discriminator loss: 0.158561, acc: 0.757812] [adversarial loss: 0.882963, acc: 0.000000]\n",
      "332: [discriminator loss: 0.198675, acc: 0.703125] [adversarial loss: 0.288396, acc: 0.406250]\n",
      "333: [discriminator loss: 0.190516, acc: 0.687500] [adversarial loss: 0.769455, acc: 0.000000]\n",
      "334: [discriminator loss: 0.200437, acc: 0.664062] [adversarial loss: 0.358867, acc: 0.187500]\n",
      "335: [discriminator loss: 0.144683, acc: 0.820312] [adversarial loss: 0.636383, acc: 0.000000]\n",
      "336: [discriminator loss: 0.147710, acc: 0.789062] [adversarial loss: 0.382410, acc: 0.140625]\n",
      "337: [discriminator loss: 0.142223, acc: 0.812500] [adversarial loss: 0.570450, acc: 0.000000]\n",
      "338: [discriminator loss: 0.149210, acc: 0.796875] [adversarial loss: 0.354962, acc: 0.187500]\n",
      "339: [discriminator loss: 0.136028, acc: 0.828125] [adversarial loss: 0.339829, acc: 0.265625]\n",
      "340: [discriminator loss: 0.143297, acc: 0.820312] [adversarial loss: 0.256063, acc: 0.531250]\n",
      "341: [discriminator loss: 0.160422, acc: 0.796875] [adversarial loss: 0.557907, acc: 0.015625]\n",
      "342: [discriminator loss: 0.139078, acc: 0.835938] [adversarial loss: 0.252633, acc: 0.468750]\n",
      "343: [discriminator loss: 0.165391, acc: 0.742188] [adversarial loss: 0.742174, acc: 0.000000]\n",
      "344: [discriminator loss: 0.174718, acc: 0.695312] [adversarial loss: 0.192551, acc: 0.765625]\n",
      "345: [discriminator loss: 0.211980, acc: 0.679688] [adversarial loss: 0.839492, acc: 0.000000]\n",
      "346: [discriminator loss: 0.240173, acc: 0.601562] [adversarial loss: 0.309590, acc: 0.328125]\n",
      "347: [discriminator loss: 0.172434, acc: 0.726562] [adversarial loss: 0.564308, acc: 0.000000]\n",
      "348: [discriminator loss: 0.145094, acc: 0.789062] [adversarial loss: 0.403004, acc: 0.078125]\n",
      "349: [discriminator loss: 0.147737, acc: 0.796875] [adversarial loss: 0.469355, acc: 0.015625]\n",
      "350: [discriminator loss: 0.165186, acc: 0.789062] [adversarial loss: 0.333578, acc: 0.156250]\n",
      "351: [discriminator loss: 0.132452, acc: 0.851562] [adversarial loss: 0.411334, acc: 0.187500]\n",
      "352: [discriminator loss: 0.144484, acc: 0.875000] [adversarial loss: 0.482156, acc: 0.000000]\n",
      "353: [discriminator loss: 0.146720, acc: 0.828125] [adversarial loss: 0.543855, acc: 0.000000]\n",
      "354: [discriminator loss: 0.127993, acc: 0.828125] [adversarial loss: 0.648836, acc: 0.015625]\n",
      "355: [discriminator loss: 0.146498, acc: 0.820312] [adversarial loss: 0.184046, acc: 0.750000]\n",
      "356: [discriminator loss: 0.153163, acc: 0.796875] [adversarial loss: 0.477080, acc: 0.046875]\n",
      "357: [discriminator loss: 0.165870, acc: 0.703125] [adversarial loss: 0.122689, acc: 0.968750]\n",
      "358: [discriminator loss: 0.231039, acc: 0.617188] [adversarial loss: 0.778596, acc: 0.000000]\n",
      "359: [discriminator loss: 0.218274, acc: 0.617188] [adversarial loss: 0.309494, acc: 0.312500]\n",
      "360: [discriminator loss: 0.172039, acc: 0.726562] [adversarial loss: 0.649648, acc: 0.000000]\n",
      "361: [discriminator loss: 0.154639, acc: 0.750000] [adversarial loss: 0.325794, acc: 0.281250]\n",
      "362: [discriminator loss: 0.178538, acc: 0.726562] [adversarial loss: 0.557134, acc: 0.031250]\n",
      "363: [discriminator loss: 0.166936, acc: 0.742188] [adversarial loss: 0.305951, acc: 0.265625]\n",
      "364: [discriminator loss: 0.140064, acc: 0.835938] [adversarial loss: 0.429666, acc: 0.062500]\n",
      "365: [discriminator loss: 0.161126, acc: 0.789062] [adversarial loss: 0.382782, acc: 0.078125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366: [discriminator loss: 0.148912, acc: 0.812500] [adversarial loss: 0.680573, acc: 0.000000]\n",
      "367: [discriminator loss: 0.156713, acc: 0.734375] [adversarial loss: 0.313096, acc: 0.328125]\n",
      "368: [discriminator loss: 0.150650, acc: 0.765625] [adversarial loss: 0.583028, acc: 0.000000]\n",
      "369: [discriminator loss: 0.151628, acc: 0.773438] [adversarial loss: 0.258895, acc: 0.531250]\n",
      "370: [discriminator loss: 0.144614, acc: 0.835938] [adversarial loss: 0.574760, acc: 0.015625]\n",
      "371: [discriminator loss: 0.167095, acc: 0.710938] [adversarial loss: 0.223075, acc: 0.656250]\n",
      "372: [discriminator loss: 0.177711, acc: 0.718750] [adversarial loss: 0.567494, acc: 0.000000]\n",
      "373: [discriminator loss: 0.156587, acc: 0.781250] [adversarial loss: 0.242079, acc: 0.562500]\n",
      "374: [discriminator loss: 0.166892, acc: 0.742188] [adversarial loss: 0.639388, acc: 0.000000]\n",
      "375: [discriminator loss: 0.176891, acc: 0.742188] [adversarial loss: 0.310207, acc: 0.281250]\n",
      "376: [discriminator loss: 0.157890, acc: 0.765625] [adversarial loss: 0.514908, acc: 0.000000]\n",
      "377: [discriminator loss: 0.151988, acc: 0.796875] [adversarial loss: 0.287361, acc: 0.421875]\n",
      "378: [discriminator loss: 0.135435, acc: 0.820312] [adversarial loss: 0.603561, acc: 0.015625]\n",
      "379: [discriminator loss: 0.169931, acc: 0.734375] [adversarial loss: 0.336948, acc: 0.156250]\n",
      "380: [discriminator loss: 0.156702, acc: 0.765625] [adversarial loss: 0.824500, acc: 0.000000]\n",
      "381: [discriminator loss: 0.158210, acc: 0.726562] [adversarial loss: 0.404198, acc: 0.140625]\n",
      "382: [discriminator loss: 0.151527, acc: 0.796875] [adversarial loss: 0.534851, acc: 0.031250]\n",
      "383: [discriminator loss: 0.161478, acc: 0.765625] [adversarial loss: 0.295005, acc: 0.406250]\n",
      "384: [discriminator loss: 0.159206, acc: 0.781250] [adversarial loss: 0.593517, acc: 0.000000]\n",
      "385: [discriminator loss: 0.159656, acc: 0.726562] [adversarial loss: 0.329917, acc: 0.312500]\n",
      "386: [discriminator loss: 0.152405, acc: 0.835938] [adversarial loss: 0.585833, acc: 0.015625]\n",
      "387: [discriminator loss: 0.153131, acc: 0.765625] [adversarial loss: 0.314105, acc: 0.312500]\n",
      "388: [discriminator loss: 0.175270, acc: 0.742188] [adversarial loss: 0.699504, acc: 0.000000]\n",
      "389: [discriminator loss: 0.191572, acc: 0.726562] [adversarial loss: 0.332197, acc: 0.296875]\n",
      "390: [discriminator loss: 0.170160, acc: 0.742188] [adversarial loss: 0.554227, acc: 0.000000]\n",
      "391: [discriminator loss: 0.161702, acc: 0.734375] [adversarial loss: 0.298385, acc: 0.328125]\n",
      "392: [discriminator loss: 0.141041, acc: 0.843750] [adversarial loss: 0.518212, acc: 0.046875]\n",
      "393: [discriminator loss: 0.166054, acc: 0.773438] [adversarial loss: 0.325316, acc: 0.218750]\n",
      "394: [discriminator loss: 0.184657, acc: 0.703125] [adversarial loss: 0.555556, acc: 0.015625]\n",
      "395: [discriminator loss: 0.163577, acc: 0.781250] [adversarial loss: 0.257377, acc: 0.515625]\n",
      "396: [discriminator loss: 0.192458, acc: 0.664062] [adversarial loss: 0.913188, acc: 0.000000]\n",
      "397: [discriminator loss: 0.206671, acc: 0.656250] [adversarial loss: 0.354375, acc: 0.218750]\n",
      "398: [discriminator loss: 0.178896, acc: 0.734375] [adversarial loss: 0.568010, acc: 0.000000]\n",
      "399: [discriminator loss: 0.194462, acc: 0.687500] [adversarial loss: 0.249714, acc: 0.531250]\n",
      "400: [discriminator loss: 0.165682, acc: 0.781250] [adversarial loss: 0.555940, acc: 0.000000]\n",
      "401: [discriminator loss: 0.156151, acc: 0.750000] [adversarial loss: 0.243944, acc: 0.500000]\n",
      "402: [discriminator loss: 0.172686, acc: 0.789062] [adversarial loss: 0.623763, acc: 0.000000]\n",
      "403: [discriminator loss: 0.155957, acc: 0.757812] [adversarial loss: 0.313662, acc: 0.250000]\n",
      "404: [discriminator loss: 0.165485, acc: 0.773438] [adversarial loss: 0.574967, acc: 0.015625]\n",
      "405: [discriminator loss: 0.167233, acc: 0.710938] [adversarial loss: 0.249706, acc: 0.500000]\n",
      "406: [discriminator loss: 0.142810, acc: 0.851562] [adversarial loss: 0.411065, acc: 0.062500]\n",
      "407: [discriminator loss: 0.149141, acc: 0.812500] [adversarial loss: 0.384430, acc: 0.156250]\n",
      "408: [discriminator loss: 0.165471, acc: 0.781250] [adversarial loss: 0.425671, acc: 0.078125]\n",
      "409: [discriminator loss: 0.136585, acc: 0.859375] [adversarial loss: 0.370913, acc: 0.156250]\n",
      "410: [discriminator loss: 0.138825, acc: 0.781250] [adversarial loss: 0.300758, acc: 0.328125]\n",
      "411: [discriminator loss: 0.137360, acc: 0.851562] [adversarial loss: 0.279290, acc: 0.421875]\n",
      "412: [discriminator loss: 0.143600, acc: 0.812500] [adversarial loss: 0.439332, acc: 0.093750]\n",
      "413: [discriminator loss: 0.133096, acc: 0.859375] [adversarial loss: 0.420535, acc: 0.125000]\n",
      "414: [discriminator loss: 0.138399, acc: 0.835938] [adversarial loss: 0.755291, acc: 0.000000]\n",
      "415: [discriminator loss: 0.203105, acc: 0.679688] [adversarial loss: 0.128123, acc: 0.875000]\n",
      "416: [discriminator loss: 0.210955, acc: 0.695312] [adversarial loss: 0.655872, acc: 0.000000]\n",
      "417: [discriminator loss: 0.270394, acc: 0.578125] [adversarial loss: 0.169489, acc: 0.859375]\n",
      "418: [discriminator loss: 0.211794, acc: 0.593750] [adversarial loss: 0.744531, acc: 0.000000]\n",
      "419: [discriminator loss: 0.141988, acc: 0.789062] [adversarial loss: 0.399448, acc: 0.171875]\n",
      "420: [discriminator loss: 0.148306, acc: 0.820312] [adversarial loss: 0.442236, acc: 0.125000]\n",
      "421: [discriminator loss: 0.122494, acc: 0.859375] [adversarial loss: 0.301281, acc: 0.406250]\n",
      "422: [discriminator loss: 0.136193, acc: 0.867188] [adversarial loss: 0.447616, acc: 0.078125]\n",
      "423: [discriminator loss: 0.142660, acc: 0.820312] [adversarial loss: 0.369246, acc: 0.203125]\n",
      "424: [discriminator loss: 0.139957, acc: 0.804688] [adversarial loss: 0.441916, acc: 0.031250]\n",
      "425: [discriminator loss: 0.136459, acc: 0.835938] [adversarial loss: 0.334933, acc: 0.281250]\n",
      "426: [discriminator loss: 0.148460, acc: 0.773438] [adversarial loss: 0.538010, acc: 0.000000]\n",
      "427: [discriminator loss: 0.144284, acc: 0.828125] [adversarial loss: 0.431673, acc: 0.140625]\n",
      "428: [discriminator loss: 0.158777, acc: 0.750000] [adversarial loss: 0.497123, acc: 0.000000]\n",
      "429: [discriminator loss: 0.126703, acc: 0.828125] [adversarial loss: 0.195471, acc: 0.656250]\n",
      "430: [discriminator loss: 0.170834, acc: 0.750000] [adversarial loss: 0.788844, acc: 0.015625]\n",
      "431: [discriminator loss: 0.225970, acc: 0.632812] [adversarial loss: 0.233520, acc: 0.593750]\n",
      "432: [discriminator loss: 0.155865, acc: 0.757812] [adversarial loss: 0.782690, acc: 0.000000]\n",
      "433: [discriminator loss: 0.141583, acc: 0.773438] [adversarial loss: 0.459489, acc: 0.062500]\n",
      "434: [discriminator loss: 0.135780, acc: 0.820312] [adversarial loss: 0.549534, acc: 0.031250]\n",
      "435: [discriminator loss: 0.141378, acc: 0.820312] [adversarial loss: 0.417397, acc: 0.187500]\n",
      "436: [discriminator loss: 0.127999, acc: 0.835938] [adversarial loss: 0.360051, acc: 0.343750]\n",
      "437: [discriminator loss: 0.130466, acc: 0.835938] [adversarial loss: 0.326373, acc: 0.312500]\n",
      "438: [discriminator loss: 0.130797, acc: 0.859375] [adversarial loss: 0.276813, acc: 0.484375]\n",
      "439: [discriminator loss: 0.169609, acc: 0.757812] [adversarial loss: 0.578887, acc: 0.015625]\n",
      "440: [discriminator loss: 0.145577, acc: 0.781250] [adversarial loss: 0.326389, acc: 0.250000]\n",
      "441: [discriminator loss: 0.142859, acc: 0.804688] [adversarial loss: 0.738396, acc: 0.000000]\n",
      "442: [discriminator loss: 0.184636, acc: 0.695312] [adversarial loss: 0.215416, acc: 0.625000]\n",
      "443: [discriminator loss: 0.183286, acc: 0.695312] [adversarial loss: 0.830233, acc: 0.000000]\n",
      "444: [discriminator loss: 0.204081, acc: 0.664062] [adversarial loss: 0.244604, acc: 0.578125]\n",
      "445: [discriminator loss: 0.157471, acc: 0.773438] [adversarial loss: 0.742624, acc: 0.000000]\n",
      "446: [discriminator loss: 0.147298, acc: 0.765625] [adversarial loss: 0.427247, acc: 0.093750]\n",
      "447: [discriminator loss: 0.140999, acc: 0.828125] [adversarial loss: 0.573079, acc: 0.031250]\n",
      "448: [discriminator loss: 0.117464, acc: 0.851562] [adversarial loss: 0.360727, acc: 0.187500]\n",
      "449: [discriminator loss: 0.150954, acc: 0.781250] [adversarial loss: 0.437254, acc: 0.109375]\n",
      "450: [discriminator loss: 0.132257, acc: 0.867188] [adversarial loss: 0.430588, acc: 0.140625]\n",
      "451: [discriminator loss: 0.118343, acc: 0.851562] [adversarial loss: 0.508804, acc: 0.031250]\n",
      "452: [discriminator loss: 0.122038, acc: 0.867188] [adversarial loss: 0.505935, acc: 0.046875]\n",
      "453: [discriminator loss: 0.129126, acc: 0.828125] [adversarial loss: 0.502409, acc: 0.062500]\n",
      "454: [discriminator loss: 0.134282, acc: 0.835938] [adversarial loss: 0.507976, acc: 0.078125]\n",
      "455: [discriminator loss: 0.123583, acc: 0.851562] [adversarial loss: 0.393788, acc: 0.109375]\n",
      "456: [discriminator loss: 0.130918, acc: 0.812500] [adversarial loss: 0.526531, acc: 0.031250]\n",
      "457: [discriminator loss: 0.116979, acc: 0.867188] [adversarial loss: 0.379518, acc: 0.234375]\n",
      "458: [discriminator loss: 0.137733, acc: 0.875000] [adversarial loss: 0.902511, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459: [discriminator loss: 0.169218, acc: 0.765625] [adversarial loss: 0.208881, acc: 0.687500]\n",
      "460: [discriminator loss: 0.250318, acc: 0.578125] [adversarial loss: 1.101082, acc: 0.000000]\n",
      "461: [discriminator loss: 0.303229, acc: 0.570312] [adversarial loss: 0.354985, acc: 0.218750]\n",
      "462: [discriminator loss: 0.159216, acc: 0.750000] [adversarial loss: 0.494605, acc: 0.031250]\n",
      "463: [discriminator loss: 0.165908, acc: 0.796875] [adversarial loss: 0.541008, acc: 0.000000]\n",
      "464: [discriminator loss: 0.130128, acc: 0.851562] [adversarial loss: 0.521840, acc: 0.046875]\n",
      "465: [discriminator loss: 0.167561, acc: 0.750000] [adversarial loss: 0.536136, acc: 0.031250]\n",
      "466: [discriminator loss: 0.153068, acc: 0.796875] [adversarial loss: 0.445473, acc: 0.140625]\n",
      "467: [discriminator loss: 0.149904, acc: 0.804688] [adversarial loss: 0.610789, acc: 0.000000]\n",
      "468: [discriminator loss: 0.131496, acc: 0.835938] [adversarial loss: 0.441940, acc: 0.109375]\n",
      "469: [discriminator loss: 0.122248, acc: 0.851562] [adversarial loss: 0.626270, acc: 0.015625]\n",
      "470: [discriminator loss: 0.126756, acc: 0.835938] [adversarial loss: 0.339901, acc: 0.312500]\n",
      "471: [discriminator loss: 0.134970, acc: 0.820312] [adversarial loss: 0.756742, acc: 0.000000]\n",
      "472: [discriminator loss: 0.153444, acc: 0.757812] [adversarial loss: 0.289085, acc: 0.406250]\n",
      "473: [discriminator loss: 0.160933, acc: 0.812500] [adversarial loss: 0.860831, acc: 0.000000]\n",
      "474: [discriminator loss: 0.183403, acc: 0.664062] [adversarial loss: 0.320174, acc: 0.312500]\n",
      "475: [discriminator loss: 0.177385, acc: 0.695312] [adversarial loss: 0.801690, acc: 0.000000]\n",
      "476: [discriminator loss: 0.132647, acc: 0.750000] [adversarial loss: 0.414932, acc: 0.156250]\n",
      "477: [discriminator loss: 0.137488, acc: 0.843750] [adversarial loss: 0.831709, acc: 0.000000]\n",
      "478: [discriminator loss: 0.154413, acc: 0.726562] [adversarial loss: 0.413511, acc: 0.093750]\n",
      "479: [discriminator loss: 0.135844, acc: 0.804688] [adversarial loss: 0.583582, acc: 0.046875]\n",
      "480: [discriminator loss: 0.124241, acc: 0.804688] [adversarial loss: 0.401647, acc: 0.218750]\n",
      "481: [discriminator loss: 0.119657, acc: 0.867188] [adversarial loss: 0.470720, acc: 0.093750]\n",
      "482: [discriminator loss: 0.128147, acc: 0.859375] [adversarial loss: 0.506002, acc: 0.046875]\n",
      "483: [discriminator loss: 0.138069, acc: 0.828125] [adversarial loss: 0.616964, acc: 0.031250]\n",
      "484: [discriminator loss: 0.118092, acc: 0.882812] [adversarial loss: 0.595713, acc: 0.062500]\n",
      "485: [discriminator loss: 0.136663, acc: 0.812500] [adversarial loss: 0.397626, acc: 0.218750]\n",
      "486: [discriminator loss: 0.119374, acc: 0.851562] [adversarial loss: 0.296595, acc: 0.500000]\n",
      "487: [discriminator loss: 0.117714, acc: 0.828125] [adversarial loss: 0.670412, acc: 0.015625]\n",
      "488: [discriminator loss: 0.165416, acc: 0.742188] [adversarial loss: 0.257379, acc: 0.546875]\n",
      "489: [discriminator loss: 0.169396, acc: 0.710938] [adversarial loss: 1.039775, acc: 0.000000]\n",
      "490: [discriminator loss: 0.203937, acc: 0.656250] [adversarial loss: 0.228097, acc: 0.609375]\n",
      "491: [discriminator loss: 0.223660, acc: 0.648438] [adversarial loss: 1.103163, acc: 0.000000]\n",
      "492: [discriminator loss: 0.196068, acc: 0.718750] [adversarial loss: 0.513530, acc: 0.093750]\n",
      "493: [discriminator loss: 0.124202, acc: 0.859375] [adversarial loss: 0.632842, acc: 0.015625]\n",
      "494: [discriminator loss: 0.129068, acc: 0.843750] [adversarial loss: 0.511090, acc: 0.109375]\n",
      "495: [discriminator loss: 0.140894, acc: 0.828125] [adversarial loss: 0.441457, acc: 0.171875]\n",
      "496: [discriminator loss: 0.110747, acc: 0.859375] [adversarial loss: 0.426294, acc: 0.109375]\n",
      "497: [discriminator loss: 0.125199, acc: 0.867188] [adversarial loss: 0.542943, acc: 0.031250]\n",
      "498: [discriminator loss: 0.114355, acc: 0.875000] [adversarial loss: 0.740345, acc: 0.015625]\n",
      "499: [discriminator loss: 0.118072, acc: 0.843750] [adversarial loss: 0.663542, acc: 0.000000]\n",
      "500: [discriminator loss: 0.116570, acc: 0.835938] [adversarial loss: 0.552965, acc: 0.093750]\n",
      "501: [discriminator loss: 0.118101, acc: 0.882812] [adversarial loss: 0.340082, acc: 0.343750]\n",
      "502: [discriminator loss: 0.112808, acc: 0.875000] [adversarial loss: 0.482556, acc: 0.062500]\n",
      "503: [discriminator loss: 0.113493, acc: 0.867188] [adversarial loss: 0.580101, acc: 0.062500]\n",
      "504: [discriminator loss: 0.121381, acc: 0.812500] [adversarial loss: 0.515242, acc: 0.093750]\n",
      "505: [discriminator loss: 0.115398, acc: 0.875000] [adversarial loss: 0.511061, acc: 0.093750]\n",
      "506: [discriminator loss: 0.150759, acc: 0.757812] [adversarial loss: 0.831915, acc: 0.000000]\n",
      "507: [discriminator loss: 0.178392, acc: 0.718750] [adversarial loss: 0.111588, acc: 0.859375]\n",
      "508: [discriminator loss: 0.286418, acc: 0.585938] [adversarial loss: 0.854046, acc: 0.000000]\n",
      "509: [discriminator loss: 0.260895, acc: 0.562500] [adversarial loss: 0.345100, acc: 0.281250]\n",
      "510: [discriminator loss: 0.152168, acc: 0.859375] [adversarial loss: 0.666561, acc: 0.015625]\n",
      "511: [discriminator loss: 0.109509, acc: 0.898438] [adversarial loss: 0.562391, acc: 0.015625]\n",
      "512: [discriminator loss: 0.127828, acc: 0.804688] [adversarial loss: 0.578562, acc: 0.062500]\n",
      "513: [discriminator loss: 0.117652, acc: 0.882812] [adversarial loss: 0.564810, acc: 0.046875]\n",
      "514: [discriminator loss: 0.108739, acc: 0.843750] [adversarial loss: 0.604791, acc: 0.031250]\n",
      "515: [discriminator loss: 0.128946, acc: 0.796875] [adversarial loss: 0.501531, acc: 0.078125]\n",
      "516: [discriminator loss: 0.114619, acc: 0.875000] [adversarial loss: 0.502826, acc: 0.093750]\n",
      "517: [discriminator loss: 0.135804, acc: 0.796875] [adversarial loss: 0.409806, acc: 0.218750]\n",
      "518: [discriminator loss: 0.123530, acc: 0.851562] [adversarial loss: 0.459661, acc: 0.093750]\n",
      "519: [discriminator loss: 0.130294, acc: 0.835938] [adversarial loss: 0.361401, acc: 0.281250]\n",
      "520: [discriminator loss: 0.137008, acc: 0.843750] [adversarial loss: 0.771082, acc: 0.000000]\n",
      "521: [discriminator loss: 0.169641, acc: 0.773438] [adversarial loss: 0.255652, acc: 0.578125]\n",
      "522: [discriminator loss: 0.192746, acc: 0.679688] [adversarial loss: 1.102904, acc: 0.000000]\n",
      "523: [discriminator loss: 0.252026, acc: 0.617188] [adversarial loss: 0.309832, acc: 0.453125]\n",
      "524: [discriminator loss: 0.186376, acc: 0.734375] [adversarial loss: 0.713259, acc: 0.015625]\n",
      "525: [discriminator loss: 0.180392, acc: 0.734375] [adversarial loss: 0.402670, acc: 0.203125]\n",
      "526: [discriminator loss: 0.144693, acc: 0.820312] [adversarial loss: 0.437514, acc: 0.156250]\n",
      "527: [discriminator loss: 0.137651, acc: 0.828125] [adversarial loss: 0.552262, acc: 0.015625]\n",
      "528: [discriminator loss: 0.147812, acc: 0.773438] [adversarial loss: 0.374055, acc: 0.203125]\n",
      "529: [discriminator loss: 0.116087, acc: 0.890625] [adversarial loss: 0.430519, acc: 0.078125]\n",
      "530: [discriminator loss: 0.134981, acc: 0.843750] [adversarial loss: 0.466955, acc: 0.140625]\n",
      "531: [discriminator loss: 0.121390, acc: 0.851562] [adversarial loss: 0.374386, acc: 0.250000]\n",
      "532: [discriminator loss: 0.119054, acc: 0.835938] [adversarial loss: 0.518603, acc: 0.078125]\n",
      "533: [discriminator loss: 0.118142, acc: 0.812500] [adversarial loss: 0.567200, acc: 0.062500]\n",
      "534: [discriminator loss: 0.101461, acc: 0.921875] [adversarial loss: 0.509733, acc: 0.093750]\n",
      "535: [discriminator loss: 0.087134, acc: 0.906250] [adversarial loss: 0.590792, acc: 0.015625]\n",
      "536: [discriminator loss: 0.122457, acc: 0.812500] [adversarial loss: 0.583167, acc: 0.046875]\n",
      "537: [discriminator loss: 0.120892, acc: 0.867188] [adversarial loss: 0.569376, acc: 0.109375]\n",
      "538: [discriminator loss: 0.124457, acc: 0.851562] [adversarial loss: 0.495405, acc: 0.093750]\n",
      "539: [discriminator loss: 0.124563, acc: 0.867188] [adversarial loss: 0.456652, acc: 0.187500]\n",
      "540: [discriminator loss: 0.131110, acc: 0.812500] [adversarial loss: 0.684239, acc: 0.062500]\n",
      "541: [discriminator loss: 0.124510, acc: 0.867188] [adversarial loss: 0.195584, acc: 0.656250]\n",
      "542: [discriminator loss: 0.209756, acc: 0.710938] [adversarial loss: 1.307495, acc: 0.000000]\n",
      "543: [discriminator loss: 0.309319, acc: 0.617188] [adversarial loss: 0.314002, acc: 0.390625]\n",
      "544: [discriminator loss: 0.174627, acc: 0.796875] [adversarial loss: 0.799272, acc: 0.000000]\n",
      "545: [discriminator loss: 0.139029, acc: 0.828125] [adversarial loss: 0.494284, acc: 0.062500]\n",
      "546: [discriminator loss: 0.129625, acc: 0.828125] [adversarial loss: 0.601719, acc: 0.046875]\n",
      "547: [discriminator loss: 0.116095, acc: 0.882812] [adversarial loss: 0.628082, acc: 0.062500]\n",
      "548: [discriminator loss: 0.114545, acc: 0.859375] [adversarial loss: 0.475195, acc: 0.140625]\n",
      "549: [discriminator loss: 0.104894, acc: 0.921875] [adversarial loss: 0.523171, acc: 0.046875]\n",
      "550: [discriminator loss: 0.112172, acc: 0.867188] [adversarial loss: 0.563244, acc: 0.125000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551: [discriminator loss: 0.103138, acc: 0.882812] [adversarial loss: 0.582298, acc: 0.093750]\n",
      "552: [discriminator loss: 0.100001, acc: 0.906250] [adversarial loss: 0.528444, acc: 0.125000]\n",
      "553: [discriminator loss: 0.128045, acc: 0.835938] [adversarial loss: 0.626238, acc: 0.062500]\n",
      "554: [discriminator loss: 0.124574, acc: 0.835938] [adversarial loss: 0.457887, acc: 0.218750]\n",
      "555: [discriminator loss: 0.117013, acc: 0.851562] [adversarial loss: 0.570434, acc: 0.062500]\n",
      "556: [discriminator loss: 0.134413, acc: 0.820312] [adversarial loss: 0.304270, acc: 0.421875]\n",
      "557: [discriminator loss: 0.142672, acc: 0.796875] [adversarial loss: 0.953573, acc: 0.000000]\n",
      "558: [discriminator loss: 0.166625, acc: 0.757812] [adversarial loss: 0.258128, acc: 0.546875]\n",
      "559: [discriminator loss: 0.166986, acc: 0.726562] [adversarial loss: 0.936246, acc: 0.031250]\n",
      "560: [discriminator loss: 0.205468, acc: 0.664062] [adversarial loss: 0.368185, acc: 0.281250]\n",
      "561: [discriminator loss: 0.149595, acc: 0.757812] [adversarial loss: 0.854996, acc: 0.000000]\n",
      "562: [discriminator loss: 0.173480, acc: 0.773438] [adversarial loss: 0.355905, acc: 0.281250]\n",
      "563: [discriminator loss: 0.172535, acc: 0.750000] [adversarial loss: 0.947528, acc: 0.000000]\n",
      "564: [discriminator loss: 0.182751, acc: 0.671875] [adversarial loss: 0.433274, acc: 0.218750]\n",
      "565: [discriminator loss: 0.124622, acc: 0.875000] [adversarial loss: 0.605021, acc: 0.015625]\n",
      "566: [discriminator loss: 0.126462, acc: 0.828125] [adversarial loss: 0.558654, acc: 0.062500]\n",
      "567: [discriminator loss: 0.108864, acc: 0.898438] [adversarial loss: 0.596799, acc: 0.031250]\n",
      "568: [discriminator loss: 0.131740, acc: 0.835938] [adversarial loss: 0.600313, acc: 0.031250]\n",
      "569: [discriminator loss: 0.132943, acc: 0.804688] [adversarial loss: 0.469068, acc: 0.203125]\n",
      "570: [discriminator loss: 0.134507, acc: 0.796875] [adversarial loss: 0.556162, acc: 0.078125]\n",
      "571: [discriminator loss: 0.154312, acc: 0.781250] [adversarial loss: 0.363526, acc: 0.328125]\n",
      "572: [discriminator loss: 0.117196, acc: 0.867188] [adversarial loss: 0.556382, acc: 0.015625]\n",
      "573: [discriminator loss: 0.112912, acc: 0.882812] [adversarial loss: 0.463295, acc: 0.109375]\n",
      "574: [discriminator loss: 0.128155, acc: 0.835938] [adversarial loss: 0.662996, acc: 0.015625]\n",
      "575: [discriminator loss: 0.130627, acc: 0.812500] [adversarial loss: 0.354014, acc: 0.375000]\n",
      "576: [discriminator loss: 0.140633, acc: 0.804688] [adversarial loss: 0.957293, acc: 0.000000]\n",
      "577: [discriminator loss: 0.154549, acc: 0.750000] [adversarial loss: 0.377456, acc: 0.328125]\n",
      "578: [discriminator loss: 0.128760, acc: 0.835938] [adversarial loss: 0.622793, acc: 0.000000]\n",
      "579: [discriminator loss: 0.139347, acc: 0.804688] [adversarial loss: 0.217618, acc: 0.703125]\n",
      "580: [discriminator loss: 0.143274, acc: 0.859375] [adversarial loss: 0.568636, acc: 0.046875]\n",
      "581: [discriminator loss: 0.141210, acc: 0.789062] [adversarial loss: 0.338357, acc: 0.328125]\n",
      "582: [discriminator loss: 0.155711, acc: 0.804688] [adversarial loss: 0.662429, acc: 0.000000]\n",
      "583: [discriminator loss: 0.108731, acc: 0.867188] [adversarial loss: 0.546395, acc: 0.093750]\n",
      "584: [discriminator loss: 0.127209, acc: 0.851562] [adversarial loss: 0.643989, acc: 0.015625]\n",
      "585: [discriminator loss: 0.143836, acc: 0.796875] [adversarial loss: 0.794874, acc: 0.000000]\n",
      "586: [discriminator loss: 0.120114, acc: 0.875000] [adversarial loss: 0.358263, acc: 0.296875]\n",
      "587: [discriminator loss: 0.122286, acc: 0.835938] [adversarial loss: 0.767457, acc: 0.000000]\n",
      "588: [discriminator loss: 0.135955, acc: 0.804688] [adversarial loss: 0.256669, acc: 0.640625]\n",
      "589: [discriminator loss: 0.162280, acc: 0.796875] [adversarial loss: 0.917914, acc: 0.000000]\n",
      "590: [discriminator loss: 0.196496, acc: 0.695312] [adversarial loss: 0.319452, acc: 0.328125]\n",
      "591: [discriminator loss: 0.166060, acc: 0.765625] [adversarial loss: 0.991311, acc: 0.000000]\n",
      "592: [discriminator loss: 0.139794, acc: 0.812500] [adversarial loss: 0.472946, acc: 0.078125]\n",
      "593: [discriminator loss: 0.140600, acc: 0.804688] [adversarial loss: 0.725737, acc: 0.015625]\n",
      "594: [discriminator loss: 0.147404, acc: 0.781250] [adversarial loss: 0.471887, acc: 0.140625]\n",
      "595: [discriminator loss: 0.144321, acc: 0.789062] [adversarial loss: 0.550018, acc: 0.031250]\n",
      "596: [discriminator loss: 0.134314, acc: 0.812500] [adversarial loss: 0.467773, acc: 0.156250]\n",
      "597: [discriminator loss: 0.112891, acc: 0.898438] [adversarial loss: 0.458963, acc: 0.140625]\n",
      "598: [discriminator loss: 0.135151, acc: 0.812500] [adversarial loss: 0.603507, acc: 0.000000]\n",
      "599: [discriminator loss: 0.119968, acc: 0.828125] [adversarial loss: 0.401510, acc: 0.171875]\n",
      "600: [discriminator loss: 0.139396, acc: 0.820312] [adversarial loss: 0.573267, acc: 0.031250]\n",
      "601: [discriminator loss: 0.124394, acc: 0.835938] [adversarial loss: 0.562735, acc: 0.031250]\n",
      "602: [discriminator loss: 0.112575, acc: 0.859375] [adversarial loss: 0.584957, acc: 0.078125]\n",
      "603: [discriminator loss: 0.121533, acc: 0.859375] [adversarial loss: 0.525229, acc: 0.109375]\n",
      "604: [discriminator loss: 0.128486, acc: 0.875000] [adversarial loss: 0.574496, acc: 0.062500]\n",
      "605: [discriminator loss: 0.139543, acc: 0.820312] [adversarial loss: 0.803744, acc: 0.000000]\n",
      "606: [discriminator loss: 0.146627, acc: 0.820312] [adversarial loss: 0.303650, acc: 0.421875]\n",
      "607: [discriminator loss: 0.164361, acc: 0.781250] [adversarial loss: 0.860727, acc: 0.015625]\n",
      "608: [discriminator loss: 0.176152, acc: 0.718750] [adversarial loss: 0.210827, acc: 0.703125]\n",
      "609: [discriminator loss: 0.225868, acc: 0.648438] [adversarial loss: 0.871139, acc: 0.000000]\n",
      "610: [discriminator loss: 0.191253, acc: 0.664062] [adversarial loss: 0.292144, acc: 0.437500]\n",
      "611: [discriminator loss: 0.153850, acc: 0.796875] [adversarial loss: 0.792783, acc: 0.015625]\n",
      "612: [discriminator loss: 0.135044, acc: 0.835938] [adversarial loss: 0.451189, acc: 0.125000]\n",
      "613: [discriminator loss: 0.118895, acc: 0.890625] [adversarial loss: 0.797420, acc: 0.000000]\n",
      "614: [discriminator loss: 0.144192, acc: 0.789062] [adversarial loss: 0.371913, acc: 0.296875]\n",
      "615: [discriminator loss: 0.114009, acc: 0.875000] [adversarial loss: 0.534544, acc: 0.109375]\n",
      "616: [discriminator loss: 0.112574, acc: 0.875000] [adversarial loss: 0.351292, acc: 0.171875]\n",
      "617: [discriminator loss: 0.100374, acc: 0.875000] [adversarial loss: 0.474785, acc: 0.125000]\n",
      "618: [discriminator loss: 0.119180, acc: 0.898438] [adversarial loss: 0.515562, acc: 0.125000]\n",
      "619: [discriminator loss: 0.152086, acc: 0.781250] [adversarial loss: 0.643558, acc: 0.062500]\n",
      "620: [discriminator loss: 0.115218, acc: 0.851562] [adversarial loss: 0.408605, acc: 0.312500]\n",
      "621: [discriminator loss: 0.168195, acc: 0.789062] [adversarial loss: 0.946372, acc: 0.000000]\n",
      "622: [discriminator loss: 0.170131, acc: 0.757812] [adversarial loss: 0.316934, acc: 0.421875]\n",
      "623: [discriminator loss: 0.152980, acc: 0.796875] [adversarial loss: 0.690231, acc: 0.078125]\n",
      "624: [discriminator loss: 0.149410, acc: 0.789062] [adversarial loss: 0.444075, acc: 0.265625]\n",
      "625: [discriminator loss: 0.117088, acc: 0.867188] [adversarial loss: 0.714060, acc: 0.031250]\n",
      "626: [discriminator loss: 0.133031, acc: 0.796875] [adversarial loss: 0.267000, acc: 0.515625]\n",
      "627: [discriminator loss: 0.118046, acc: 0.875000] [adversarial loss: 0.577462, acc: 0.109375]\n",
      "628: [discriminator loss: 0.091168, acc: 0.914062] [adversarial loss: 0.506406, acc: 0.109375]\n",
      "629: [discriminator loss: 0.138642, acc: 0.820312] [adversarial loss: 0.685469, acc: 0.046875]\n",
      "630: [discriminator loss: 0.143414, acc: 0.773438] [adversarial loss: 0.285364, acc: 0.546875]\n",
      "631: [discriminator loss: 0.137674, acc: 0.804688] [adversarial loss: 0.861131, acc: 0.000000]\n",
      "632: [discriminator loss: 0.152988, acc: 0.742188] [adversarial loss: 0.352111, acc: 0.312500]\n",
      "633: [discriminator loss: 0.140844, acc: 0.851562] [adversarial loss: 0.848556, acc: 0.015625]\n",
      "634: [discriminator loss: 0.158385, acc: 0.750000] [adversarial loss: 0.417251, acc: 0.234375]\n",
      "635: [discriminator loss: 0.133373, acc: 0.859375] [adversarial loss: 0.765141, acc: 0.015625]\n",
      "636: [discriminator loss: 0.155043, acc: 0.750000] [adversarial loss: 0.292668, acc: 0.531250]\n",
      "637: [discriminator loss: 0.141689, acc: 0.812500] [adversarial loss: 0.694063, acc: 0.031250]\n",
      "638: [discriminator loss: 0.129767, acc: 0.835938] [adversarial loss: 0.611039, acc: 0.046875]\n",
      "639: [discriminator loss: 0.128567, acc: 0.820312] [adversarial loss: 0.492520, acc: 0.093750]\n",
      "640: [discriminator loss: 0.104817, acc: 0.859375] [adversarial loss: 0.718773, acc: 0.046875]\n",
      "641: [discriminator loss: 0.134050, acc: 0.828125] [adversarial loss: 0.403094, acc: 0.265625]\n",
      "642: [discriminator loss: 0.139183, acc: 0.851562] [adversarial loss: 0.685168, acc: 0.000000]\n",
      "643: [discriminator loss: 0.143691, acc: 0.804688] [adversarial loss: 0.499247, acc: 0.093750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644: [discriminator loss: 0.132903, acc: 0.835938] [adversarial loss: 0.663749, acc: 0.015625]\n",
      "645: [discriminator loss: 0.119773, acc: 0.851562] [adversarial loss: 0.766132, acc: 0.000000]\n",
      "646: [discriminator loss: 0.144867, acc: 0.773438] [adversarial loss: 0.306160, acc: 0.437500]\n",
      "647: [discriminator loss: 0.155726, acc: 0.765625] [adversarial loss: 0.883441, acc: 0.000000]\n",
      "648: [discriminator loss: 0.200283, acc: 0.695312] [adversarial loss: 0.200248, acc: 0.687500]\n",
      "649: [discriminator loss: 0.168304, acc: 0.734375] [adversarial loss: 0.842460, acc: 0.000000]\n",
      "650: [discriminator loss: 0.145445, acc: 0.742188] [adversarial loss: 0.416798, acc: 0.171875]\n",
      "651: [discriminator loss: 0.122546, acc: 0.867188] [adversarial loss: 0.733575, acc: 0.031250]\n",
      "652: [discriminator loss: 0.121952, acc: 0.835938] [adversarial loss: 0.500564, acc: 0.109375]\n",
      "653: [discriminator loss: 0.118986, acc: 0.859375] [adversarial loss: 0.542120, acc: 0.093750]\n",
      "654: [discriminator loss: 0.105512, acc: 0.875000] [adversarial loss: 0.439984, acc: 0.234375]\n",
      "655: [discriminator loss: 0.147168, acc: 0.804688] [adversarial loss: 0.677262, acc: 0.031250]\n",
      "656: [discriminator loss: 0.137339, acc: 0.851562] [adversarial loss: 0.447988, acc: 0.125000]\n",
      "657: [discriminator loss: 0.152873, acc: 0.773438] [adversarial loss: 0.680839, acc: 0.015625]\n",
      "658: [discriminator loss: 0.118711, acc: 0.851562] [adversarial loss: 0.565449, acc: 0.062500]\n",
      "659: [discriminator loss: 0.105258, acc: 0.914062] [adversarial loss: 0.791847, acc: 0.015625]\n",
      "660: [discriminator loss: 0.149717, acc: 0.773438] [adversarial loss: 0.356503, acc: 0.281250]\n",
      "661: [discriminator loss: 0.144199, acc: 0.804688] [adversarial loss: 0.955181, acc: 0.015625]\n",
      "662: [discriminator loss: 0.161225, acc: 0.718750] [adversarial loss: 0.314593, acc: 0.406250]\n",
      "663: [discriminator loss: 0.173818, acc: 0.710938] [adversarial loss: 0.841113, acc: 0.000000]\n",
      "664: [discriminator loss: 0.139789, acc: 0.789062] [adversarial loss: 0.472163, acc: 0.109375]\n",
      "665: [discriminator loss: 0.114792, acc: 0.898438] [adversarial loss: 0.733793, acc: 0.031250]\n",
      "666: [discriminator loss: 0.143592, acc: 0.742188] [adversarial loss: 0.325873, acc: 0.437500]\n",
      "667: [discriminator loss: 0.147983, acc: 0.789062] [adversarial loss: 0.926769, acc: 0.000000]\n",
      "668: [discriminator loss: 0.184516, acc: 0.742188] [adversarial loss: 0.338412, acc: 0.359375]\n",
      "669: [discriminator loss: 0.150746, acc: 0.804688] [adversarial loss: 0.612725, acc: 0.046875]\n",
      "670: [discriminator loss: 0.140442, acc: 0.796875] [adversarial loss: 0.504794, acc: 0.140625]\n",
      "671: [discriminator loss: 0.123570, acc: 0.843750] [adversarial loss: 0.588923, acc: 0.062500]\n",
      "672: [discriminator loss: 0.121939, acc: 0.882812] [adversarial loss: 0.444183, acc: 0.187500]\n",
      "673: [discriminator loss: 0.127685, acc: 0.835938] [adversarial loss: 0.824615, acc: 0.031250]\n",
      "674: [discriminator loss: 0.145850, acc: 0.796875] [adversarial loss: 0.483535, acc: 0.156250]\n",
      "675: [discriminator loss: 0.113203, acc: 0.843750] [adversarial loss: 0.761050, acc: 0.000000]\n",
      "676: [discriminator loss: 0.118221, acc: 0.843750] [adversarial loss: 0.447728, acc: 0.187500]\n",
      "677: [discriminator loss: 0.129252, acc: 0.835938] [adversarial loss: 0.612468, acc: 0.000000]\n",
      "678: [discriminator loss: 0.124872, acc: 0.804688] [adversarial loss: 0.388551, acc: 0.281250]\n",
      "679: [discriminator loss: 0.143661, acc: 0.812500] [adversarial loss: 0.965922, acc: 0.000000]\n",
      "680: [discriminator loss: 0.163459, acc: 0.750000] [adversarial loss: 0.315899, acc: 0.375000]\n",
      "681: [discriminator loss: 0.129647, acc: 0.890625] [adversarial loss: 0.759652, acc: 0.000000]\n",
      "682: [discriminator loss: 0.137413, acc: 0.812500] [adversarial loss: 0.390804, acc: 0.281250]\n",
      "683: [discriminator loss: 0.181487, acc: 0.757812] [adversarial loss: 0.641864, acc: 0.015625]\n",
      "684: [discriminator loss: 0.147322, acc: 0.812500] [adversarial loss: 0.427593, acc: 0.156250]\n",
      "685: [discriminator loss: 0.141979, acc: 0.828125] [adversarial loss: 0.596858, acc: 0.093750]\n",
      "686: [discriminator loss: 0.124854, acc: 0.828125] [adversarial loss: 0.418275, acc: 0.109375]\n",
      "687: [discriminator loss: 0.134124, acc: 0.812500] [adversarial loss: 0.683602, acc: 0.093750]\n",
      "688: [discriminator loss: 0.117912, acc: 0.859375] [adversarial loss: 0.442844, acc: 0.203125]\n",
      "689: [discriminator loss: 0.135001, acc: 0.828125] [adversarial loss: 0.893415, acc: 0.046875]\n",
      "690: [discriminator loss: 0.141030, acc: 0.804688] [adversarial loss: 0.320199, acc: 0.453125]\n",
      "691: [discriminator loss: 0.215089, acc: 0.695312] [adversarial loss: 0.900319, acc: 0.031250]\n",
      "692: [discriminator loss: 0.169529, acc: 0.750000] [adversarial loss: 0.377701, acc: 0.296875]\n",
      "693: [discriminator loss: 0.134985, acc: 0.828125] [adversarial loss: 0.701792, acc: 0.000000]\n",
      "694: [discriminator loss: 0.130840, acc: 0.835938] [adversarial loss: 0.493745, acc: 0.109375]\n",
      "695: [discriminator loss: 0.136150, acc: 0.835938] [adversarial loss: 0.500982, acc: 0.171875]\n",
      "696: [discriminator loss: 0.131870, acc: 0.835938] [adversarial loss: 0.429473, acc: 0.171875]\n",
      "697: [discriminator loss: 0.141264, acc: 0.789062] [adversarial loss: 0.568562, acc: 0.078125]\n",
      "698: [discriminator loss: 0.118763, acc: 0.867188] [adversarial loss: 0.562383, acc: 0.140625]\n",
      "699: [discriminator loss: 0.134074, acc: 0.796875] [adversarial loss: 0.523059, acc: 0.125000]\n",
      "700: [discriminator loss: 0.123259, acc: 0.820312] [adversarial loss: 0.696843, acc: 0.015625]\n",
      "701: [discriminator loss: 0.126077, acc: 0.812500] [adversarial loss: 0.402398, acc: 0.265625]\n",
      "702: [discriminator loss: 0.134708, acc: 0.828125] [adversarial loss: 0.835734, acc: 0.015625]\n",
      "703: [discriminator loss: 0.165537, acc: 0.750000] [adversarial loss: 0.282144, acc: 0.500000]\n",
      "704: [discriminator loss: 0.154370, acc: 0.820312] [adversarial loss: 0.705797, acc: 0.015625]\n",
      "705: [discriminator loss: 0.129559, acc: 0.812500] [adversarial loss: 0.433345, acc: 0.171875]\n",
      "706: [discriminator loss: 0.139564, acc: 0.859375] [adversarial loss: 0.650350, acc: 0.046875]\n",
      "707: [discriminator loss: 0.117573, acc: 0.859375] [adversarial loss: 0.441481, acc: 0.171875]\n",
      "708: [discriminator loss: 0.135761, acc: 0.828125] [adversarial loss: 0.892937, acc: 0.062500]\n",
      "709: [discriminator loss: 0.170081, acc: 0.734375] [adversarial loss: 0.394924, acc: 0.265625]\n",
      "710: [discriminator loss: 0.121825, acc: 0.890625] [adversarial loss: 0.699834, acc: 0.046875]\n",
      "711: [discriminator loss: 0.150561, acc: 0.765625] [adversarial loss: 0.322441, acc: 0.390625]\n",
      "712: [discriminator loss: 0.189430, acc: 0.734375] [adversarial loss: 0.878839, acc: 0.015625]\n",
      "713: [discriminator loss: 0.172575, acc: 0.750000] [adversarial loss: 0.368964, acc: 0.359375]\n",
      "714: [discriminator loss: 0.162658, acc: 0.757812] [adversarial loss: 0.651378, acc: 0.046875]\n",
      "715: [discriminator loss: 0.132081, acc: 0.796875] [adversarial loss: 0.412877, acc: 0.265625]\n",
      "716: [discriminator loss: 0.142339, acc: 0.765625] [adversarial loss: 0.774988, acc: 0.000000]\n",
      "717: [discriminator loss: 0.143369, acc: 0.781250] [adversarial loss: 0.361853, acc: 0.328125]\n",
      "718: [discriminator loss: 0.149416, acc: 0.789062] [adversarial loss: 0.631134, acc: 0.062500]\n",
      "719: [discriminator loss: 0.151004, acc: 0.750000] [adversarial loss: 0.396144, acc: 0.218750]\n",
      "720: [discriminator loss: 0.156296, acc: 0.781250] [adversarial loss: 0.709148, acc: 0.015625]\n",
      "721: [discriminator loss: 0.141531, acc: 0.796875] [adversarial loss: 0.484767, acc: 0.156250]\n",
      "722: [discriminator loss: 0.127991, acc: 0.851562] [adversarial loss: 0.539172, acc: 0.062500]\n",
      "723: [discriminator loss: 0.141616, acc: 0.820312] [adversarial loss: 0.461245, acc: 0.234375]\n",
      "724: [discriminator loss: 0.125242, acc: 0.835938] [adversarial loss: 0.438556, acc: 0.171875]\n",
      "725: [discriminator loss: 0.099785, acc: 0.875000] [adversarial loss: 0.412328, acc: 0.265625]\n",
      "726: [discriminator loss: 0.130600, acc: 0.835938] [adversarial loss: 0.692792, acc: 0.062500]\n",
      "727: [discriminator loss: 0.140607, acc: 0.804688] [adversarial loss: 0.356997, acc: 0.328125]\n",
      "728: [discriminator loss: 0.137607, acc: 0.804688] [adversarial loss: 0.841026, acc: 0.046875]\n",
      "729: [discriminator loss: 0.167354, acc: 0.757812] [adversarial loss: 0.283357, acc: 0.453125]\n",
      "730: [discriminator loss: 0.217117, acc: 0.710938] [adversarial loss: 0.893807, acc: 0.015625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731: [discriminator loss: 0.230325, acc: 0.625000] [adversarial loss: 0.379195, acc: 0.296875]\n",
      "732: [discriminator loss: 0.181355, acc: 0.687500] [adversarial loss: 0.691900, acc: 0.031250]\n",
      "733: [discriminator loss: 0.149968, acc: 0.757812] [adversarial loss: 0.435244, acc: 0.328125]\n",
      "734: [discriminator loss: 0.131694, acc: 0.796875] [adversarial loss: 0.668692, acc: 0.062500]\n",
      "735: [discriminator loss: 0.125266, acc: 0.812500] [adversarial loss: 0.406850, acc: 0.296875]\n",
      "736: [discriminator loss: 0.130861, acc: 0.820312] [adversarial loss: 0.517140, acc: 0.093750]\n",
      "737: [discriminator loss: 0.127613, acc: 0.851562] [adversarial loss: 0.479283, acc: 0.171875]\n",
      "738: [discriminator loss: 0.144785, acc: 0.789062] [adversarial loss: 0.502210, acc: 0.109375]\n",
      "739: [discriminator loss: 0.104675, acc: 0.882812] [adversarial loss: 0.466372, acc: 0.187500]\n",
      "740: [discriminator loss: 0.137390, acc: 0.820312] [adversarial loss: 0.549863, acc: 0.109375]\n",
      "741: [discriminator loss: 0.148936, acc: 0.804688] [adversarial loss: 0.449038, acc: 0.234375]\n",
      "742: [discriminator loss: 0.137000, acc: 0.781250] [adversarial loss: 0.599147, acc: 0.140625]\n",
      "743: [discriminator loss: 0.141518, acc: 0.781250] [adversarial loss: 0.550102, acc: 0.078125]\n",
      "744: [discriminator loss: 0.124575, acc: 0.828125] [adversarial loss: 0.443697, acc: 0.218750]\n",
      "745: [discriminator loss: 0.127934, acc: 0.812500] [adversarial loss: 0.820915, acc: 0.046875]\n",
      "746: [discriminator loss: 0.153177, acc: 0.789062] [adversarial loss: 0.287397, acc: 0.468750]\n",
      "747: [discriminator loss: 0.184904, acc: 0.718750] [adversarial loss: 0.963050, acc: 0.015625]\n",
      "748: [discriminator loss: 0.189030, acc: 0.718750] [adversarial loss: 0.270245, acc: 0.562500]\n",
      "749: [discriminator loss: 0.181815, acc: 0.687500] [adversarial loss: 0.694110, acc: 0.062500]\n",
      "750: [discriminator loss: 0.161141, acc: 0.742188] [adversarial loss: 0.494840, acc: 0.187500]\n",
      "751: [discriminator loss: 0.110216, acc: 0.906250] [adversarial loss: 0.671540, acc: 0.046875]\n",
      "752: [discriminator loss: 0.124953, acc: 0.851562] [adversarial loss: 0.545611, acc: 0.109375]\n",
      "753: [discriminator loss: 0.161805, acc: 0.796875] [adversarial loss: 0.572465, acc: 0.171875]\n",
      "754: [discriminator loss: 0.157115, acc: 0.781250] [adversarial loss: 0.494222, acc: 0.218750]\n",
      "755: [discriminator loss: 0.125159, acc: 0.851562] [adversarial loss: 0.742950, acc: 0.046875]\n",
      "756: [discriminator loss: 0.129064, acc: 0.828125] [adversarial loss: 0.359997, acc: 0.281250]\n",
      "757: [discriminator loss: 0.186106, acc: 0.765625] [adversarial loss: 0.928577, acc: 0.000000]\n",
      "758: [discriminator loss: 0.185704, acc: 0.695312] [adversarial loss: 0.341726, acc: 0.343750]\n",
      "759: [discriminator loss: 0.150131, acc: 0.781250] [adversarial loss: 0.680081, acc: 0.015625]\n",
      "760: [discriminator loss: 0.151940, acc: 0.804688] [adversarial loss: 0.475008, acc: 0.171875]\n",
      "761: [discriminator loss: 0.131962, acc: 0.828125] [adversarial loss: 0.459142, acc: 0.234375]\n",
      "762: [discriminator loss: 0.152955, acc: 0.789062] [adversarial loss: 0.652674, acc: 0.046875]\n",
      "763: [discriminator loss: 0.132991, acc: 0.843750] [adversarial loss: 0.470748, acc: 0.250000]\n",
      "764: [discriminator loss: 0.132762, acc: 0.820312] [adversarial loss: 0.663792, acc: 0.062500]\n",
      "765: [discriminator loss: 0.158817, acc: 0.757812] [adversarial loss: 0.495565, acc: 0.218750]\n",
      "766: [discriminator loss: 0.146503, acc: 0.812500] [adversarial loss: 0.576146, acc: 0.140625]\n",
      "767: [discriminator loss: 0.140812, acc: 0.781250] [adversarial loss: 0.480297, acc: 0.156250]\n",
      "768: [discriminator loss: 0.157161, acc: 0.781250] [adversarial loss: 0.501077, acc: 0.218750]\n",
      "769: [discriminator loss: 0.129906, acc: 0.804688] [adversarial loss: 0.559910, acc: 0.140625]\n",
      "770: [discriminator loss: 0.112792, acc: 0.851562] [adversarial loss: 0.423327, acc: 0.281250]\n",
      "771: [discriminator loss: 0.124951, acc: 0.851562] [adversarial loss: 0.853301, acc: 0.062500]\n",
      "772: [discriminator loss: 0.201302, acc: 0.687500] [adversarial loss: 0.150349, acc: 0.828125]\n",
      "773: [discriminator loss: 0.261805, acc: 0.625000] [adversarial loss: 1.169414, acc: 0.015625]\n",
      "774: [discriminator loss: 0.254515, acc: 0.671875] [adversarial loss: 0.416217, acc: 0.250000]\n",
      "775: [discriminator loss: 0.140330, acc: 0.804688] [adversarial loss: 0.517534, acc: 0.140625]\n",
      "776: [discriminator loss: 0.143239, acc: 0.773438] [adversarial loss: 0.483542, acc: 0.156250]\n",
      "777: [discriminator loss: 0.145733, acc: 0.843750] [adversarial loss: 0.559205, acc: 0.093750]\n",
      "778: [discriminator loss: 0.130174, acc: 0.835938] [adversarial loss: 0.490190, acc: 0.171875]\n",
      "779: [discriminator loss: 0.138679, acc: 0.828125] [adversarial loss: 0.500102, acc: 0.156250]\n",
      "780: [discriminator loss: 0.129277, acc: 0.851562] [adversarial loss: 0.555587, acc: 0.093750]\n",
      "781: [discriminator loss: 0.147676, acc: 0.789062] [adversarial loss: 0.549014, acc: 0.156250]\n",
      "782: [discriminator loss: 0.153621, acc: 0.804688] [adversarial loss: 0.487568, acc: 0.171875]\n",
      "783: [discriminator loss: 0.145482, acc: 0.820312] [adversarial loss: 0.682439, acc: 0.078125]\n",
      "784: [discriminator loss: 0.156681, acc: 0.734375] [adversarial loss: 0.398622, acc: 0.203125]\n",
      "785: [discriminator loss: 0.150536, acc: 0.789062] [adversarial loss: 0.760144, acc: 0.015625]\n",
      "786: [discriminator loss: 0.129234, acc: 0.835938] [adversarial loss: 0.393325, acc: 0.359375]\n",
      "787: [discriminator loss: 0.150115, acc: 0.781250] [adversarial loss: 0.731616, acc: 0.078125]\n",
      "788: [discriminator loss: 0.132170, acc: 0.796875] [adversarial loss: 0.331708, acc: 0.390625]\n",
      "789: [discriminator loss: 0.160190, acc: 0.781250] [adversarial loss: 0.716175, acc: 0.031250]\n",
      "790: [discriminator loss: 0.159684, acc: 0.742188] [adversarial loss: 0.356345, acc: 0.406250]\n",
      "791: [discriminator loss: 0.155072, acc: 0.812500] [adversarial loss: 0.596471, acc: 0.171875]\n",
      "792: [discriminator loss: 0.159149, acc: 0.750000] [adversarial loss: 0.345475, acc: 0.375000]\n",
      "793: [discriminator loss: 0.144185, acc: 0.804688] [adversarial loss: 0.712297, acc: 0.062500]\n",
      "794: [discriminator loss: 0.129316, acc: 0.835938] [adversarial loss: 0.425660, acc: 0.281250]\n",
      "795: [discriminator loss: 0.141628, acc: 0.812500] [adversarial loss: 0.696864, acc: 0.078125]\n",
      "796: [discriminator loss: 0.156344, acc: 0.750000] [adversarial loss: 0.359165, acc: 0.296875]\n",
      "797: [discriminator loss: 0.149496, acc: 0.773438] [adversarial loss: 0.762055, acc: 0.046875]\n",
      "798: [discriminator loss: 0.131169, acc: 0.820312] [adversarial loss: 0.448670, acc: 0.203125]\n",
      "799: [discriminator loss: 0.167242, acc: 0.726562] [adversarial loss: 0.679234, acc: 0.062500]\n",
      "800: [discriminator loss: 0.140569, acc: 0.804688] [adversarial loss: 0.510165, acc: 0.109375]\n",
      "801: [discriminator loss: 0.148070, acc: 0.765625] [adversarial loss: 0.536574, acc: 0.109375]\n",
      "802: [discriminator loss: 0.124002, acc: 0.835938] [adversarial loss: 0.415666, acc: 0.250000]\n",
      "803: [discriminator loss: 0.144589, acc: 0.843750] [adversarial loss: 0.748974, acc: 0.000000]\n",
      "804: [discriminator loss: 0.178314, acc: 0.710938] [adversarial loss: 0.341093, acc: 0.375000]\n",
      "805: [discriminator loss: 0.138669, acc: 0.804688] [adversarial loss: 0.640301, acc: 0.078125]\n",
      "806: [discriminator loss: 0.154229, acc: 0.773438] [adversarial loss: 0.409367, acc: 0.265625]\n",
      "807: [discriminator loss: 0.141381, acc: 0.804688] [adversarial loss: 0.614477, acc: 0.078125]\n",
      "808: [discriminator loss: 0.144000, acc: 0.835938] [adversarial loss: 0.555322, acc: 0.187500]\n",
      "809: [discriminator loss: 0.137660, acc: 0.828125] [adversarial loss: 0.582824, acc: 0.125000]\n",
      "810: [discriminator loss: 0.149874, acc: 0.820312] [adversarial loss: 0.690719, acc: 0.125000]\n",
      "811: [discriminator loss: 0.145444, acc: 0.828125] [adversarial loss: 0.358604, acc: 0.312500]\n",
      "812: [discriminator loss: 0.169151, acc: 0.750000] [adversarial loss: 0.825154, acc: 0.015625]\n",
      "813: [discriminator loss: 0.191506, acc: 0.679688] [adversarial loss: 0.294778, acc: 0.500000]\n",
      "814: [discriminator loss: 0.227080, acc: 0.601562] [adversarial loss: 0.839970, acc: 0.015625]\n",
      "815: [discriminator loss: 0.203671, acc: 0.656250] [adversarial loss: 0.344620, acc: 0.281250]\n",
      "816: [discriminator loss: 0.161086, acc: 0.781250] [adversarial loss: 0.667619, acc: 0.078125]\n",
      "817: [discriminator loss: 0.136732, acc: 0.828125] [adversarial loss: 0.463826, acc: 0.296875]\n",
      "818: [discriminator loss: 0.150696, acc: 0.757812] [adversarial loss: 0.498728, acc: 0.125000]\n",
      "819: [discriminator loss: 0.142766, acc: 0.828125] [adversarial loss: 0.534918, acc: 0.109375]\n",
      "820: [discriminator loss: 0.134726, acc: 0.820312] [adversarial loss: 0.507962, acc: 0.125000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821: [discriminator loss: 0.128827, acc: 0.835938] [adversarial loss: 0.579950, acc: 0.125000]\n",
      "822: [discriminator loss: 0.126563, acc: 0.851562] [adversarial loss: 0.565935, acc: 0.140625]\n",
      "823: [discriminator loss: 0.122120, acc: 0.828125] [adversarial loss: 0.332845, acc: 0.421875]\n",
      "824: [discriminator loss: 0.155978, acc: 0.796875] [adversarial loss: 0.855608, acc: 0.000000]\n",
      "825: [discriminator loss: 0.155109, acc: 0.765625] [adversarial loss: 0.329741, acc: 0.406250]\n",
      "826: [discriminator loss: 0.163525, acc: 0.750000] [adversarial loss: 0.766630, acc: 0.062500]\n",
      "827: [discriminator loss: 0.167134, acc: 0.773438] [adversarial loss: 0.392284, acc: 0.328125]\n",
      "828: [discriminator loss: 0.123168, acc: 0.882812] [adversarial loss: 0.651709, acc: 0.078125]\n",
      "829: [discriminator loss: 0.197956, acc: 0.687500] [adversarial loss: 0.404766, acc: 0.375000]\n",
      "830: [discriminator loss: 0.174077, acc: 0.718750] [adversarial loss: 0.640230, acc: 0.046875]\n",
      "831: [discriminator loss: 0.156657, acc: 0.773438] [adversarial loss: 0.439627, acc: 0.250000]\n",
      "832: [discriminator loss: 0.132899, acc: 0.843750] [adversarial loss: 0.665858, acc: 0.093750]\n",
      "833: [discriminator loss: 0.159233, acc: 0.757812] [adversarial loss: 0.437136, acc: 0.125000]\n",
      "834: [discriminator loss: 0.137262, acc: 0.820312] [adversarial loss: 0.714959, acc: 0.000000]\n",
      "835: [discriminator loss: 0.157244, acc: 0.726562] [adversarial loss: 0.317801, acc: 0.421875]\n",
      "836: [discriminator loss: 0.172688, acc: 0.757812] [adversarial loss: 0.714469, acc: 0.078125]\n",
      "837: [discriminator loss: 0.147479, acc: 0.750000] [adversarial loss: 0.394506, acc: 0.312500]\n",
      "838: [discriminator loss: 0.164261, acc: 0.765625] [adversarial loss: 0.791709, acc: 0.031250]\n",
      "839: [discriminator loss: 0.167789, acc: 0.734375] [adversarial loss: 0.400583, acc: 0.218750]\n",
      "840: [discriminator loss: 0.161468, acc: 0.789062] [adversarial loss: 0.708589, acc: 0.015625]\n",
      "841: [discriminator loss: 0.160943, acc: 0.757812] [adversarial loss: 0.379095, acc: 0.265625]\n",
      "842: [discriminator loss: 0.177493, acc: 0.734375] [adversarial loss: 0.617053, acc: 0.000000]\n",
      "843: [discriminator loss: 0.162614, acc: 0.765625] [adversarial loss: 0.426627, acc: 0.281250]\n",
      "844: [discriminator loss: 0.146682, acc: 0.812500] [adversarial loss: 0.737862, acc: 0.046875]\n",
      "845: [discriminator loss: 0.171542, acc: 0.742188] [adversarial loss: 0.355211, acc: 0.421875]\n",
      "846: [discriminator loss: 0.168280, acc: 0.734375] [adversarial loss: 0.769738, acc: 0.015625]\n",
      "847: [discriminator loss: 0.167509, acc: 0.750000] [adversarial loss: 0.362046, acc: 0.328125]\n",
      "848: [discriminator loss: 0.155254, acc: 0.765625] [adversarial loss: 0.749111, acc: 0.062500]\n",
      "849: [discriminator loss: 0.188108, acc: 0.757812] [adversarial loss: 0.420302, acc: 0.250000]\n",
      "850: [discriminator loss: 0.139241, acc: 0.851562] [adversarial loss: 0.587145, acc: 0.109375]\n",
      "851: [discriminator loss: 0.145172, acc: 0.820312] [adversarial loss: 0.456395, acc: 0.296875]\n",
      "852: [discriminator loss: 0.144175, acc: 0.820312] [adversarial loss: 0.590473, acc: 0.046875]\n",
      "853: [discriminator loss: 0.129202, acc: 0.835938] [adversarial loss: 0.497395, acc: 0.156250]\n",
      "854: [discriminator loss: 0.129619, acc: 0.867188] [adversarial loss: 0.413487, acc: 0.187500]\n",
      "855: [discriminator loss: 0.158807, acc: 0.781250] [adversarial loss: 0.376498, acc: 0.312500]\n",
      "856: [discriminator loss: 0.161296, acc: 0.750000] [adversarial loss: 0.656862, acc: 0.093750]\n",
      "857: [discriminator loss: 0.156718, acc: 0.773438] [adversarial loss: 0.355931, acc: 0.359375]\n",
      "858: [discriminator loss: 0.147573, acc: 0.773438] [adversarial loss: 0.885847, acc: 0.015625]\n",
      "859: [discriminator loss: 0.200929, acc: 0.656250] [adversarial loss: 0.286282, acc: 0.421875]\n",
      "860: [discriminator loss: 0.170023, acc: 0.765625] [adversarial loss: 0.690528, acc: 0.015625]\n",
      "861: [discriminator loss: 0.195325, acc: 0.695312] [adversarial loss: 0.376763, acc: 0.296875]\n",
      "862: [discriminator loss: 0.157344, acc: 0.828125] [adversarial loss: 0.786824, acc: 0.031250]\n",
      "863: [discriminator loss: 0.188980, acc: 0.710938] [adversarial loss: 0.444936, acc: 0.187500]\n",
      "864: [discriminator loss: 0.130024, acc: 0.828125] [adversarial loss: 0.543195, acc: 0.156250]\n",
      "865: [discriminator loss: 0.136574, acc: 0.843750] [adversarial loss: 0.473645, acc: 0.171875]\n",
      "866: [discriminator loss: 0.139119, acc: 0.875000] [adversarial loss: 0.595132, acc: 0.125000]\n",
      "867: [discriminator loss: 0.152449, acc: 0.757812] [adversarial loss: 0.505141, acc: 0.187500]\n",
      "868: [discriminator loss: 0.131715, acc: 0.859375] [adversarial loss: 0.549801, acc: 0.093750]\n",
      "869: [discriminator loss: 0.130243, acc: 0.859375] [adversarial loss: 0.577698, acc: 0.109375]\n",
      "870: [discriminator loss: 0.151618, acc: 0.750000] [adversarial loss: 0.479714, acc: 0.171875]\n",
      "871: [discriminator loss: 0.132671, acc: 0.843750] [adversarial loss: 0.544962, acc: 0.171875]\n",
      "872: [discriminator loss: 0.134690, acc: 0.804688] [adversarial loss: 0.497215, acc: 0.203125]\n",
      "873: [discriminator loss: 0.138786, acc: 0.835938] [adversarial loss: 0.782898, acc: 0.015625]\n",
      "874: [discriminator loss: 0.159076, acc: 0.789062] [adversarial loss: 0.304028, acc: 0.406250]\n",
      "875: [discriminator loss: 0.165857, acc: 0.765625] [adversarial loss: 0.931939, acc: 0.031250]\n",
      "876: [discriminator loss: 0.219982, acc: 0.648438] [adversarial loss: 0.270699, acc: 0.500000]\n",
      "877: [discriminator loss: 0.170186, acc: 0.757812] [adversarial loss: 0.740576, acc: 0.015625]\n",
      "878: [discriminator loss: 0.160097, acc: 0.757812] [adversarial loss: 0.354219, acc: 0.218750]\n",
      "879: [discriminator loss: 0.176655, acc: 0.695312] [adversarial loss: 0.704223, acc: 0.062500]\n",
      "880: [discriminator loss: 0.143057, acc: 0.812500] [adversarial loss: 0.466940, acc: 0.250000]\n",
      "881: [discriminator loss: 0.139722, acc: 0.882812] [adversarial loss: 0.587337, acc: 0.093750]\n",
      "882: [discriminator loss: 0.148974, acc: 0.804688] [adversarial loss: 0.475139, acc: 0.203125]\n",
      "883: [discriminator loss: 0.160666, acc: 0.742188] [adversarial loss: 0.493967, acc: 0.187500]\n",
      "884: [discriminator loss: 0.186399, acc: 0.710938] [adversarial loss: 0.533346, acc: 0.125000]\n",
      "885: [discriminator loss: 0.136435, acc: 0.867188] [adversarial loss: 0.474070, acc: 0.140625]\n",
      "886: [discriminator loss: 0.155291, acc: 0.781250] [adversarial loss: 0.608033, acc: 0.093750]\n",
      "887: [discriminator loss: 0.170083, acc: 0.726562] [adversarial loss: 0.412472, acc: 0.281250]\n",
      "888: [discriminator loss: 0.151068, acc: 0.789062] [adversarial loss: 0.593533, acc: 0.109375]\n",
      "889: [discriminator loss: 0.156221, acc: 0.757812] [adversarial loss: 0.379541, acc: 0.296875]\n",
      "890: [discriminator loss: 0.187282, acc: 0.742188] [adversarial loss: 0.712719, acc: 0.078125]\n",
      "891: [discriminator loss: 0.165029, acc: 0.757812] [adversarial loss: 0.340240, acc: 0.343750]\n",
      "892: [discriminator loss: 0.140965, acc: 0.820312] [adversarial loss: 0.730878, acc: 0.062500]\n",
      "893: [discriminator loss: 0.157504, acc: 0.781250] [adversarial loss: 0.328694, acc: 0.328125]\n",
      "894: [discriminator loss: 0.185197, acc: 0.695312] [adversarial loss: 0.675766, acc: 0.078125]\n",
      "895: [discriminator loss: 0.150579, acc: 0.789062] [adversarial loss: 0.448785, acc: 0.218750]\n",
      "896: [discriminator loss: 0.174803, acc: 0.750000] [adversarial loss: 0.543923, acc: 0.125000]\n",
      "897: [discriminator loss: 0.162730, acc: 0.757812] [adversarial loss: 0.372632, acc: 0.328125]\n",
      "898: [discriminator loss: 0.180401, acc: 0.726562] [adversarial loss: 0.810288, acc: 0.000000]\n",
      "899: [discriminator loss: 0.161284, acc: 0.765625] [adversarial loss: 0.358206, acc: 0.406250]\n",
      "900: [discriminator loss: 0.171050, acc: 0.718750] [adversarial loss: 0.764707, acc: 0.062500]\n",
      "901: [discriminator loss: 0.145585, acc: 0.820312] [adversarial loss: 0.343839, acc: 0.359375]\n",
      "902: [discriminator loss: 0.164849, acc: 0.773438] [adversarial loss: 0.721509, acc: 0.046875]\n",
      "903: [discriminator loss: 0.165430, acc: 0.773438] [adversarial loss: 0.390715, acc: 0.281250]\n",
      "904: [discriminator loss: 0.185420, acc: 0.726562] [adversarial loss: 0.422033, acc: 0.218750]\n",
      "905: [discriminator loss: 0.145835, acc: 0.796875] [adversarial loss: 0.497681, acc: 0.171875]\n",
      "906: [discriminator loss: 0.144765, acc: 0.812500] [adversarial loss: 0.541830, acc: 0.140625]\n",
      "907: [discriminator loss: 0.139275, acc: 0.828125] [adversarial loss: 0.465145, acc: 0.187500]\n",
      "908: [discriminator loss: 0.147462, acc: 0.757812] [adversarial loss: 0.421729, acc: 0.250000]\n",
      "909: [discriminator loss: 0.153099, acc: 0.781250] [adversarial loss: 0.587789, acc: 0.187500]\n",
      "910: [discriminator loss: 0.143152, acc: 0.789062] [adversarial loss: 0.579898, acc: 0.093750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911: [discriminator loss: 0.131145, acc: 0.851562] [adversarial loss: 0.373156, acc: 0.359375]\n",
      "912: [discriminator loss: 0.156905, acc: 0.789062] [adversarial loss: 0.785552, acc: 0.015625]\n",
      "913: [discriminator loss: 0.157057, acc: 0.789062] [adversarial loss: 0.372135, acc: 0.250000]\n",
      "914: [discriminator loss: 0.171828, acc: 0.734375] [adversarial loss: 0.675641, acc: 0.062500]\n",
      "915: [discriminator loss: 0.152325, acc: 0.726562] [adversarial loss: 0.354856, acc: 0.296875]\n",
      "916: [discriminator loss: 0.138931, acc: 0.812500] [adversarial loss: 0.689557, acc: 0.046875]\n",
      "917: [discriminator loss: 0.162100, acc: 0.773438] [adversarial loss: 0.309478, acc: 0.453125]\n",
      "918: [discriminator loss: 0.177806, acc: 0.742188] [adversarial loss: 0.795332, acc: 0.000000]\n",
      "919: [discriminator loss: 0.161629, acc: 0.789062] [adversarial loss: 0.349151, acc: 0.359375]\n",
      "920: [discriminator loss: 0.152076, acc: 0.773438] [adversarial loss: 0.675961, acc: 0.078125]\n",
      "921: [discriminator loss: 0.151984, acc: 0.773438] [adversarial loss: 0.364432, acc: 0.296875]\n",
      "922: [discriminator loss: 0.150618, acc: 0.812500] [adversarial loss: 0.609006, acc: 0.093750]\n",
      "923: [discriminator loss: 0.152566, acc: 0.781250] [adversarial loss: 0.417256, acc: 0.218750]\n",
      "924: [discriminator loss: 0.145704, acc: 0.835938] [adversarial loss: 0.638501, acc: 0.062500]\n",
      "925: [discriminator loss: 0.151016, acc: 0.820312] [adversarial loss: 0.521806, acc: 0.171875]\n",
      "926: [discriminator loss: 0.145772, acc: 0.804688] [adversarial loss: 0.611213, acc: 0.031250]\n",
      "927: [discriminator loss: 0.135272, acc: 0.828125] [adversarial loss: 0.491376, acc: 0.125000]\n",
      "928: [discriminator loss: 0.138678, acc: 0.812500] [adversarial loss: 0.660245, acc: 0.062500]\n",
      "929: [discriminator loss: 0.145285, acc: 0.820312] [adversarial loss: 0.563556, acc: 0.140625]\n",
      "930: [discriminator loss: 0.168065, acc: 0.757812] [adversarial loss: 0.702808, acc: 0.062500]\n",
      "931: [discriminator loss: 0.155211, acc: 0.812500] [adversarial loss: 0.404876, acc: 0.265625]\n",
      "932: [discriminator loss: 0.142207, acc: 0.789062] [adversarial loss: 0.717520, acc: 0.062500]\n",
      "933: [discriminator loss: 0.126432, acc: 0.820312] [adversarial loss: 0.432295, acc: 0.281250]\n",
      "934: [discriminator loss: 0.168843, acc: 0.781250] [adversarial loss: 0.925068, acc: 0.000000]\n",
      "935: [discriminator loss: 0.197934, acc: 0.773438] [adversarial loss: 0.331999, acc: 0.359375]\n",
      "936: [discriminator loss: 0.164395, acc: 0.796875] [adversarial loss: 0.806794, acc: 0.000000]\n",
      "937: [discriminator loss: 0.150757, acc: 0.789062] [adversarial loss: 0.348512, acc: 0.312500]\n",
      "938: [discriminator loss: 0.128669, acc: 0.859375] [adversarial loss: 0.598539, acc: 0.093750]\n",
      "939: [discriminator loss: 0.153866, acc: 0.765625] [adversarial loss: 0.554633, acc: 0.140625]\n",
      "940: [discriminator loss: 0.137227, acc: 0.828125] [adversarial loss: 0.607096, acc: 0.078125]\n",
      "941: [discriminator loss: 0.161989, acc: 0.765625] [adversarial loss: 0.531829, acc: 0.125000]\n",
      "942: [discriminator loss: 0.160953, acc: 0.750000] [adversarial loss: 0.545199, acc: 0.171875]\n",
      "943: [discriminator loss: 0.125903, acc: 0.843750] [adversarial loss: 0.596291, acc: 0.046875]\n",
      "944: [discriminator loss: 0.139149, acc: 0.835938] [adversarial loss: 0.353310, acc: 0.421875]\n",
      "945: [discriminator loss: 0.182609, acc: 0.710938] [adversarial loss: 0.832346, acc: 0.000000]\n",
      "946: [discriminator loss: 0.202907, acc: 0.710938] [adversarial loss: 0.321019, acc: 0.453125]\n",
      "947: [discriminator loss: 0.198733, acc: 0.734375] [adversarial loss: 0.715123, acc: 0.046875]\n",
      "948: [discriminator loss: 0.170102, acc: 0.710938] [adversarial loss: 0.400948, acc: 0.265625]\n",
      "949: [discriminator loss: 0.167388, acc: 0.765625] [adversarial loss: 0.648466, acc: 0.062500]\n",
      "950: [discriminator loss: 0.162857, acc: 0.757812] [adversarial loss: 0.523176, acc: 0.187500]\n",
      "951: [discriminator loss: 0.140646, acc: 0.835938] [adversarial loss: 0.599143, acc: 0.093750]\n",
      "952: [discriminator loss: 0.155709, acc: 0.789062] [adversarial loss: 0.521967, acc: 0.078125]\n",
      "953: [discriminator loss: 0.139646, acc: 0.796875] [adversarial loss: 0.517738, acc: 0.187500]\n",
      "954: [discriminator loss: 0.140698, acc: 0.820312] [adversarial loss: 0.428445, acc: 0.265625]\n",
      "955: [discriminator loss: 0.137490, acc: 0.804688] [adversarial loss: 0.636516, acc: 0.078125]\n",
      "956: [discriminator loss: 0.159087, acc: 0.757812] [adversarial loss: 0.388240, acc: 0.328125]\n",
      "957: [discriminator loss: 0.187744, acc: 0.750000] [adversarial loss: 0.727904, acc: 0.031250]\n",
      "958: [discriminator loss: 0.209167, acc: 0.664062] [adversarial loss: 0.383842, acc: 0.234375]\n",
      "959: [discriminator loss: 0.142366, acc: 0.789062] [adversarial loss: 0.578830, acc: 0.093750]\n",
      "960: [discriminator loss: 0.139377, acc: 0.843750] [adversarial loss: 0.392255, acc: 0.281250]\n",
      "961: [discriminator loss: 0.182368, acc: 0.757812] [adversarial loss: 0.776394, acc: 0.031250]\n",
      "962: [discriminator loss: 0.159737, acc: 0.750000] [adversarial loss: 0.352335, acc: 0.343750]\n",
      "963: [discriminator loss: 0.150053, acc: 0.796875] [adversarial loss: 0.680895, acc: 0.046875]\n",
      "964: [discriminator loss: 0.141885, acc: 0.796875] [adversarial loss: 0.398367, acc: 0.312500]\n",
      "965: [discriminator loss: 0.142006, acc: 0.812500] [adversarial loss: 0.601264, acc: 0.125000]\n",
      "966: [discriminator loss: 0.150340, acc: 0.765625] [adversarial loss: 0.490423, acc: 0.156250]\n",
      "967: [discriminator loss: 0.143639, acc: 0.804688] [adversarial loss: 0.657697, acc: 0.078125]\n",
      "968: [discriminator loss: 0.126351, acc: 0.820312] [adversarial loss: 0.590298, acc: 0.156250]\n",
      "969: [discriminator loss: 0.156929, acc: 0.773438] [adversarial loss: 0.479540, acc: 0.125000]\n",
      "970: [discriminator loss: 0.159373, acc: 0.789062] [adversarial loss: 0.521982, acc: 0.265625]\n",
      "971: [discriminator loss: 0.185327, acc: 0.726562] [adversarial loss: 0.624918, acc: 0.078125]\n",
      "972: [discriminator loss: 0.172047, acc: 0.734375] [adversarial loss: 0.652346, acc: 0.109375]\n",
      "973: [discriminator loss: 0.149448, acc: 0.773438] [adversarial loss: 0.360339, acc: 0.343750]\n",
      "974: [discriminator loss: 0.171294, acc: 0.773438] [adversarial loss: 0.884399, acc: 0.000000]\n",
      "975: [discriminator loss: 0.192455, acc: 0.710938] [adversarial loss: 0.353644, acc: 0.390625]\n",
      "976: [discriminator loss: 0.159434, acc: 0.734375] [adversarial loss: 0.799314, acc: 0.015625]\n",
      "977: [discriminator loss: 0.185152, acc: 0.734375] [adversarial loss: 0.364270, acc: 0.343750]\n",
      "978: [discriminator loss: 0.160328, acc: 0.734375] [adversarial loss: 0.623121, acc: 0.046875]\n",
      "979: [discriminator loss: 0.142402, acc: 0.796875] [adversarial loss: 0.463351, acc: 0.250000]\n",
      "980: [discriminator loss: 0.136169, acc: 0.812500] [adversarial loss: 0.517597, acc: 0.156250]\n",
      "981: [discriminator loss: 0.153643, acc: 0.734375] [adversarial loss: 0.534565, acc: 0.156250]\n",
      "982: [discriminator loss: 0.141822, acc: 0.812500] [adversarial loss: 0.564360, acc: 0.140625]\n",
      "983: [discriminator loss: 0.141861, acc: 0.804688] [adversarial loss: 0.552487, acc: 0.109375]\n",
      "984: [discriminator loss: 0.167507, acc: 0.804688] [adversarial loss: 0.442245, acc: 0.265625]\n",
      "985: [discriminator loss: 0.139059, acc: 0.812500] [adversarial loss: 0.523825, acc: 0.109375]\n",
      "986: [discriminator loss: 0.144695, acc: 0.796875] [adversarial loss: 0.578827, acc: 0.156250]\n",
      "987: [discriminator loss: 0.135897, acc: 0.820312] [adversarial loss: 0.405802, acc: 0.265625]\n",
      "988: [discriminator loss: 0.166795, acc: 0.773438] [adversarial loss: 0.674700, acc: 0.125000]\n",
      "989: [discriminator loss: 0.199981, acc: 0.679688] [adversarial loss: 0.489515, acc: 0.171875]\n",
      "990: [discriminator loss: 0.135223, acc: 0.828125] [adversarial loss: 0.704874, acc: 0.062500]\n",
      "991: [discriminator loss: 0.134392, acc: 0.812500] [adversarial loss: 0.485746, acc: 0.171875]\n",
      "992: [discriminator loss: 0.137520, acc: 0.859375] [adversarial loss: 0.647043, acc: 0.046875]\n",
      "993: [discriminator loss: 0.168266, acc: 0.750000] [adversarial loss: 0.462565, acc: 0.265625]\n",
      "994: [discriminator loss: 0.123120, acc: 0.835938] [adversarial loss: 0.639922, acc: 0.109375]\n",
      "995: [discriminator loss: 0.148320, acc: 0.804688] [adversarial loss: 0.661684, acc: 0.093750]\n",
      "996: [discriminator loss: 0.140004, acc: 0.781250] [adversarial loss: 0.499519, acc: 0.218750]\n",
      "997: [discriminator loss: 0.153485, acc: 0.796875] [adversarial loss: 0.519261, acc: 0.156250]\n",
      "998: [discriminator loss: 0.149897, acc: 0.804688] [adversarial loss: 0.622253, acc: 0.093750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999: [discriminator loss: 0.160280, acc: 0.773438] [adversarial loss: 0.260595, acc: 0.578125]\n",
      "1000: [discriminator loss: 0.187288, acc: 0.765625] [adversarial loss: 0.989555, acc: 0.015625]\n",
      "1001: [discriminator loss: 0.236029, acc: 0.625000] [adversarial loss: 0.345412, acc: 0.343750]\n",
      "1002: [discriminator loss: 0.170425, acc: 0.718750] [adversarial loss: 0.670683, acc: 0.093750]\n",
      "1003: [discriminator loss: 0.140492, acc: 0.812500] [adversarial loss: 0.451844, acc: 0.203125]\n",
      "1004: [discriminator loss: 0.141250, acc: 0.835938] [adversarial loss: 0.562031, acc: 0.109375]\n",
      "1005: [discriminator loss: 0.124069, acc: 0.843750] [adversarial loss: 0.561486, acc: 0.125000]\n",
      "1006: [discriminator loss: 0.131601, acc: 0.851562] [adversarial loss: 0.421418, acc: 0.250000]\n",
      "1007: [discriminator loss: 0.139247, acc: 0.820312] [adversarial loss: 0.605770, acc: 0.046875]\n",
      "1008: [discriminator loss: 0.135687, acc: 0.828125] [adversarial loss: 0.559236, acc: 0.125000]\n",
      "1009: [discriminator loss: 0.160118, acc: 0.757812] [adversarial loss: 0.521112, acc: 0.171875]\n",
      "1010: [discriminator loss: 0.159854, acc: 0.750000] [adversarial loss: 0.661181, acc: 0.093750]\n",
      "1011: [discriminator loss: 0.163423, acc: 0.765625] [adversarial loss: 0.534661, acc: 0.187500]\n",
      "1012: [discriminator loss: 0.149204, acc: 0.773438] [adversarial loss: 0.574011, acc: 0.156250]\n",
      "1013: [discriminator loss: 0.129585, acc: 0.820312] [adversarial loss: 0.499085, acc: 0.140625]\n",
      "1014: [discriminator loss: 0.146291, acc: 0.796875] [adversarial loss: 0.488810, acc: 0.203125]\n",
      "1015: [discriminator loss: 0.146182, acc: 0.820312] [adversarial loss: 0.618580, acc: 0.125000]\n",
      "1016: [discriminator loss: 0.161243, acc: 0.742188] [adversarial loss: 0.369499, acc: 0.328125]\n",
      "1017: [discriminator loss: 0.164191, acc: 0.750000] [adversarial loss: 0.721012, acc: 0.031250]\n",
      "1018: [discriminator loss: 0.160708, acc: 0.781250] [adversarial loss: 0.326967, acc: 0.421875]\n",
      "1019: [discriminator loss: 0.162695, acc: 0.765625] [adversarial loss: 0.854387, acc: 0.031250]\n",
      "1020: [discriminator loss: 0.211138, acc: 0.718750] [adversarial loss: 0.245668, acc: 0.578125]\n",
      "1021: [discriminator loss: 0.202205, acc: 0.679688] [adversarial loss: 0.744622, acc: 0.062500]\n",
      "1022: [discriminator loss: 0.178722, acc: 0.757812] [adversarial loss: 0.418600, acc: 0.265625]\n",
      "1023: [discriminator loss: 0.202748, acc: 0.664062] [adversarial loss: 0.758893, acc: 0.015625]\n",
      "1024: [discriminator loss: 0.140787, acc: 0.804688] [adversarial loss: 0.368656, acc: 0.281250]\n",
      "1025: [discriminator loss: 0.158059, acc: 0.796875] [adversarial loss: 0.698351, acc: 0.015625]\n",
      "1026: [discriminator loss: 0.152487, acc: 0.781250] [adversarial loss: 0.455033, acc: 0.218750]\n",
      "1027: [discriminator loss: 0.133102, acc: 0.820312] [adversarial loss: 0.640605, acc: 0.093750]\n",
      "1028: [discriminator loss: 0.121454, acc: 0.867188] [adversarial loss: 0.456881, acc: 0.125000]\n",
      "1029: [discriminator loss: 0.122065, acc: 0.867188] [adversarial loss: 0.612810, acc: 0.093750]\n",
      "1030: [discriminator loss: 0.149828, acc: 0.781250] [adversarial loss: 0.517422, acc: 0.171875]\n",
      "1031: [discriminator loss: 0.131806, acc: 0.835938] [adversarial loss: 0.540177, acc: 0.203125]\n",
      "1032: [discriminator loss: 0.162600, acc: 0.804688] [adversarial loss: 0.445750, acc: 0.234375]\n",
      "1033: [discriminator loss: 0.140010, acc: 0.812500] [adversarial loss: 0.637249, acc: 0.109375]\n",
      "1034: [discriminator loss: 0.169873, acc: 0.757812] [adversarial loss: 0.391483, acc: 0.187500]\n",
      "1035: [discriminator loss: 0.158508, acc: 0.789062] [adversarial loss: 0.822465, acc: 0.031250]\n",
      "1036: [discriminator loss: 0.167744, acc: 0.742188] [adversarial loss: 0.354353, acc: 0.406250]\n",
      "1037: [discriminator loss: 0.171476, acc: 0.750000] [adversarial loss: 0.677821, acc: 0.046875]\n",
      "1038: [discriminator loss: 0.155626, acc: 0.781250] [adversarial loss: 0.346122, acc: 0.375000]\n",
      "1039: [discriminator loss: 0.175510, acc: 0.750000] [adversarial loss: 0.772892, acc: 0.046875]\n",
      "1040: [discriminator loss: 0.166879, acc: 0.734375] [adversarial loss: 0.404143, acc: 0.281250]\n",
      "1041: [discriminator loss: 0.169053, acc: 0.773438] [adversarial loss: 0.666925, acc: 0.031250]\n",
      "1042: [discriminator loss: 0.144015, acc: 0.789062] [adversarial loss: 0.376163, acc: 0.265625]\n",
      "1043: [discriminator loss: 0.141721, acc: 0.820312] [adversarial loss: 0.646476, acc: 0.015625]\n",
      "1044: [discriminator loss: 0.149136, acc: 0.804688] [adversarial loss: 0.464836, acc: 0.234375]\n",
      "1045: [discriminator loss: 0.140549, acc: 0.820312] [adversarial loss: 0.543889, acc: 0.125000]\n",
      "1046: [discriminator loss: 0.149228, acc: 0.812500] [adversarial loss: 0.470610, acc: 0.218750]\n",
      "1047: [discriminator loss: 0.133172, acc: 0.843750] [adversarial loss: 0.524190, acc: 0.125000]\n",
      "1048: [discriminator loss: 0.135891, acc: 0.835938] [adversarial loss: 0.481145, acc: 0.187500]\n",
      "1049: [discriminator loss: 0.125813, acc: 0.804688] [adversarial loss: 0.571582, acc: 0.093750]\n",
      "1050: [discriminator loss: 0.154654, acc: 0.765625] [adversarial loss: 0.539905, acc: 0.156250]\n",
      "1051: [discriminator loss: 0.147467, acc: 0.804688] [adversarial loss: 0.678614, acc: 0.078125]\n",
      "1052: [discriminator loss: 0.156205, acc: 0.789062] [adversarial loss: 0.324649, acc: 0.343750]\n",
      "1053: [discriminator loss: 0.148167, acc: 0.804688] [adversarial loss: 0.784407, acc: 0.015625]\n",
      "1054: [discriminator loss: 0.205311, acc: 0.671875] [adversarial loss: 0.366915, acc: 0.343750]\n",
      "1055: [discriminator loss: 0.195570, acc: 0.703125] [adversarial loss: 0.832989, acc: 0.000000]\n",
      "1056: [discriminator loss: 0.162225, acc: 0.773438] [adversarial loss: 0.380709, acc: 0.343750]\n",
      "1057: [discriminator loss: 0.146116, acc: 0.812500] [adversarial loss: 0.727921, acc: 0.093750]\n",
      "1058: [discriminator loss: 0.167050, acc: 0.710938] [adversarial loss: 0.471012, acc: 0.203125]\n",
      "1059: [discriminator loss: 0.133805, acc: 0.796875] [adversarial loss: 0.696895, acc: 0.062500]\n",
      "1060: [discriminator loss: 0.140745, acc: 0.796875] [adversarial loss: 0.517576, acc: 0.140625]\n",
      "1061: [discriminator loss: 0.149967, acc: 0.789062] [adversarial loss: 0.579193, acc: 0.109375]\n",
      "1062: [discriminator loss: 0.141390, acc: 0.804688] [adversarial loss: 0.613138, acc: 0.093750]\n",
      "1063: [discriminator loss: 0.138558, acc: 0.812500] [adversarial loss: 0.410182, acc: 0.343750]\n",
      "1064: [discriminator loss: 0.159265, acc: 0.796875] [adversarial loss: 0.644638, acc: 0.093750]\n",
      "1065: [discriminator loss: 0.158212, acc: 0.765625] [adversarial loss: 0.365271, acc: 0.328125]\n",
      "1066: [discriminator loss: 0.166448, acc: 0.734375] [adversarial loss: 0.828417, acc: 0.031250]\n",
      "1067: [discriminator loss: 0.162776, acc: 0.734375] [adversarial loss: 0.317253, acc: 0.484375]\n",
      "1068: [discriminator loss: 0.162393, acc: 0.734375] [adversarial loss: 0.718484, acc: 0.031250]\n",
      "1069: [discriminator loss: 0.150608, acc: 0.804688] [adversarial loss: 0.427438, acc: 0.218750]\n",
      "1070: [discriminator loss: 0.157866, acc: 0.773438] [adversarial loss: 0.609532, acc: 0.093750]\n",
      "1071: [discriminator loss: 0.159351, acc: 0.757812] [adversarial loss: 0.351871, acc: 0.312500]\n",
      "1072: [discriminator loss: 0.166594, acc: 0.781250] [adversarial loss: 0.637619, acc: 0.125000]\n",
      "1073: [discriminator loss: 0.165045, acc: 0.750000] [adversarial loss: 0.357096, acc: 0.359375]\n",
      "1074: [discriminator loss: 0.168553, acc: 0.750000] [adversarial loss: 0.638085, acc: 0.062500]\n",
      "1075: [discriminator loss: 0.161717, acc: 0.796875] [adversarial loss: 0.504459, acc: 0.218750]\n",
      "1076: [discriminator loss: 0.133504, acc: 0.828125] [adversarial loss: 0.593047, acc: 0.109375]\n",
      "1077: [discriminator loss: 0.141525, acc: 0.789062] [adversarial loss: 0.494152, acc: 0.140625]\n",
      "1078: [discriminator loss: 0.147979, acc: 0.835938] [adversarial loss: 0.647705, acc: 0.078125]\n",
      "1079: [discriminator loss: 0.160117, acc: 0.796875] [adversarial loss: 0.351411, acc: 0.343750]\n",
      "1080: [discriminator loss: 0.170829, acc: 0.734375] [adversarial loss: 0.707486, acc: 0.078125]\n",
      "1081: [discriminator loss: 0.140737, acc: 0.812500] [adversarial loss: 0.475901, acc: 0.187500]\n",
      "1082: [discriminator loss: 0.173531, acc: 0.734375] [adversarial loss: 0.734179, acc: 0.062500]\n",
      "1083: [discriminator loss: 0.162096, acc: 0.757812] [adversarial loss: 0.389499, acc: 0.359375]\n",
      "1084: [discriminator loss: 0.175901, acc: 0.789062] [adversarial loss: 0.747270, acc: 0.031250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085: [discriminator loss: 0.165162, acc: 0.726562] [adversarial loss: 0.410684, acc: 0.265625]\n",
      "1086: [discriminator loss: 0.178358, acc: 0.742188] [adversarial loss: 0.582735, acc: 0.140625]\n",
      "1087: [discriminator loss: 0.135655, acc: 0.804688] [adversarial loss: 0.442085, acc: 0.265625]\n",
      "1088: [discriminator loss: 0.158791, acc: 0.781250] [adversarial loss: 0.628121, acc: 0.187500]\n",
      "1089: [discriminator loss: 0.147404, acc: 0.804688] [adversarial loss: 0.385545, acc: 0.375000]\n",
      "1090: [discriminator loss: 0.143458, acc: 0.796875] [adversarial loss: 0.579324, acc: 0.109375]\n",
      "1091: [discriminator loss: 0.156256, acc: 0.773438] [adversarial loss: 0.429501, acc: 0.312500]\n",
      "1092: [discriminator loss: 0.202954, acc: 0.695312] [adversarial loss: 0.568147, acc: 0.187500]\n",
      "1093: [discriminator loss: 0.155899, acc: 0.820312] [adversarial loss: 0.646258, acc: 0.046875]\n",
      "1094: [discriminator loss: 0.134845, acc: 0.804688] [adversarial loss: 0.438978, acc: 0.312500]\n",
      "1095: [discriminator loss: 0.173655, acc: 0.710938] [adversarial loss: 0.868377, acc: 0.000000]\n",
      "1096: [discriminator loss: 0.207811, acc: 0.710938] [adversarial loss: 0.386692, acc: 0.312500]\n",
      "1097: [discriminator loss: 0.152809, acc: 0.835938] [adversarial loss: 0.518039, acc: 0.125000]\n",
      "1098: [discriminator loss: 0.151381, acc: 0.781250] [adversarial loss: 0.364736, acc: 0.359375]\n",
      "1099: [discriminator loss: 0.159198, acc: 0.773438] [adversarial loss: 0.724863, acc: 0.031250]\n",
      "1100: [discriminator loss: 0.156149, acc: 0.773438] [adversarial loss: 0.421731, acc: 0.328125]\n",
      "1101: [discriminator loss: 0.159252, acc: 0.742188] [adversarial loss: 0.630893, acc: 0.109375]\n",
      "1102: [discriminator loss: 0.151432, acc: 0.789062] [adversarial loss: 0.380398, acc: 0.328125]\n",
      "1103: [discriminator loss: 0.162681, acc: 0.718750] [adversarial loss: 0.699790, acc: 0.046875]\n",
      "1104: [discriminator loss: 0.161027, acc: 0.765625] [adversarial loss: 0.315441, acc: 0.406250]\n",
      "1105: [discriminator loss: 0.156484, acc: 0.796875] [adversarial loss: 0.688720, acc: 0.062500]\n",
      "1106: [discriminator loss: 0.127897, acc: 0.828125] [adversarial loss: 0.338376, acc: 0.390625]\n",
      "1107: [discriminator loss: 0.170326, acc: 0.726562] [adversarial loss: 0.626998, acc: 0.046875]\n",
      "1108: [discriminator loss: 0.135285, acc: 0.820312] [adversarial loss: 0.372223, acc: 0.328125]\n",
      "1109: [discriminator loss: 0.182021, acc: 0.718750] [adversarial loss: 0.647993, acc: 0.015625]\n",
      "1110: [discriminator loss: 0.173135, acc: 0.718750] [adversarial loss: 0.472122, acc: 0.156250]\n",
      "1111: [discriminator loss: 0.148250, acc: 0.804688] [adversarial loss: 0.569771, acc: 0.125000]\n",
      "1112: [discriminator loss: 0.140318, acc: 0.781250] [adversarial loss: 0.458104, acc: 0.171875]\n",
      "1113: [discriminator loss: 0.139275, acc: 0.812500] [adversarial loss: 0.542044, acc: 0.125000]\n",
      "1114: [discriminator loss: 0.138559, acc: 0.812500] [adversarial loss: 0.662987, acc: 0.062500]\n",
      "1115: [discriminator loss: 0.163650, acc: 0.742188] [adversarial loss: 0.428433, acc: 0.296875]\n",
      "1116: [discriminator loss: 0.156004, acc: 0.781250] [adversarial loss: 0.609510, acc: 0.140625]\n",
      "1117: [discriminator loss: 0.171031, acc: 0.757812] [adversarial loss: 0.443225, acc: 0.234375]\n",
      "1118: [discriminator loss: 0.155899, acc: 0.750000] [adversarial loss: 0.924838, acc: 0.015625]\n",
      "1119: [discriminator loss: 0.178775, acc: 0.718750] [adversarial loss: 0.307745, acc: 0.546875]\n",
      "1120: [discriminator loss: 0.142086, acc: 0.812500] [adversarial loss: 0.678314, acc: 0.078125]\n",
      "1121: [discriminator loss: 0.157634, acc: 0.773438] [adversarial loss: 0.402913, acc: 0.265625]\n",
      "1122: [discriminator loss: 0.156711, acc: 0.781250] [adversarial loss: 0.658783, acc: 0.093750]\n",
      "1123: [discriminator loss: 0.153326, acc: 0.828125] [adversarial loss: 0.383264, acc: 0.328125]\n",
      "1124: [discriminator loss: 0.160143, acc: 0.773438] [adversarial loss: 0.661313, acc: 0.046875]\n",
      "1125: [discriminator loss: 0.147679, acc: 0.804688] [adversarial loss: 0.494211, acc: 0.171875]\n",
      "1126: [discriminator loss: 0.135988, acc: 0.812500] [adversarial loss: 0.638515, acc: 0.093750]\n",
      "1127: [discriminator loss: 0.146454, acc: 0.796875] [adversarial loss: 0.425182, acc: 0.281250]\n",
      "1128: [discriminator loss: 0.133599, acc: 0.843750] [adversarial loss: 0.528868, acc: 0.125000]\n",
      "1129: [discriminator loss: 0.140453, acc: 0.843750] [adversarial loss: 0.513862, acc: 0.125000]\n",
      "1130: [discriminator loss: 0.147726, acc: 0.804688] [adversarial loss: 0.525791, acc: 0.156250]\n",
      "1131: [discriminator loss: 0.149798, acc: 0.789062] [adversarial loss: 0.432034, acc: 0.281250]\n",
      "1132: [discriminator loss: 0.150542, acc: 0.835938] [adversarial loss: 0.631838, acc: 0.109375]\n",
      "1133: [discriminator loss: 0.146633, acc: 0.796875] [adversarial loss: 0.311549, acc: 0.390625]\n",
      "1134: [discriminator loss: 0.166089, acc: 0.757812] [adversarial loss: 0.893301, acc: 0.031250]\n",
      "1135: [discriminator loss: 0.185302, acc: 0.726562] [adversarial loss: 0.400082, acc: 0.359375]\n",
      "1136: [discriminator loss: 0.152383, acc: 0.750000] [adversarial loss: 0.832610, acc: 0.046875]\n",
      "1137: [discriminator loss: 0.168523, acc: 0.750000] [adversarial loss: 0.378248, acc: 0.328125]\n",
      "1138: [discriminator loss: 0.153112, acc: 0.781250] [adversarial loss: 0.711993, acc: 0.046875]\n",
      "1139: [discriminator loss: 0.139738, acc: 0.796875] [adversarial loss: 0.390139, acc: 0.390625]\n",
      "1140: [discriminator loss: 0.160531, acc: 0.773438] [adversarial loss: 0.754841, acc: 0.031250]\n",
      "1141: [discriminator loss: 0.163511, acc: 0.773438] [adversarial loss: 0.386951, acc: 0.312500]\n",
      "1142: [discriminator loss: 0.177122, acc: 0.773438] [adversarial loss: 0.618535, acc: 0.062500]\n",
      "1143: [discriminator loss: 0.144447, acc: 0.820312] [adversarial loss: 0.482217, acc: 0.140625]\n",
      "1144: [discriminator loss: 0.152464, acc: 0.781250] [adversarial loss: 0.505397, acc: 0.156250]\n",
      "1145: [discriminator loss: 0.139737, acc: 0.796875] [adversarial loss: 0.452817, acc: 0.203125]\n",
      "1146: [discriminator loss: 0.135625, acc: 0.828125] [adversarial loss: 0.750665, acc: 0.046875]\n",
      "1147: [discriminator loss: 0.144918, acc: 0.820312] [adversarial loss: 0.409835, acc: 0.250000]\n",
      "1148: [discriminator loss: 0.169783, acc: 0.789062] [adversarial loss: 0.695662, acc: 0.046875]\n",
      "1149: [discriminator loss: 0.143195, acc: 0.789062] [adversarial loss: 0.484678, acc: 0.187500]\n",
      "1150: [discriminator loss: 0.120991, acc: 0.851562] [adversarial loss: 0.548927, acc: 0.109375]\n",
      "1151: [discriminator loss: 0.150654, acc: 0.781250] [adversarial loss: 0.493402, acc: 0.250000]\n",
      "1152: [discriminator loss: 0.131792, acc: 0.820312] [adversarial loss: 0.639397, acc: 0.078125]\n",
      "1153: [discriminator loss: 0.148066, acc: 0.789062] [adversarial loss: 0.395127, acc: 0.296875]\n",
      "1154: [discriminator loss: 0.185395, acc: 0.710938] [adversarial loss: 0.901653, acc: 0.000000]\n",
      "1155: [discriminator loss: 0.178477, acc: 0.734375] [adversarial loss: 0.321176, acc: 0.343750]\n",
      "1156: [discriminator loss: 0.184882, acc: 0.679688] [adversarial loss: 0.741834, acc: 0.062500]\n",
      "1157: [discriminator loss: 0.137222, acc: 0.828125] [adversarial loss: 0.353559, acc: 0.328125]\n",
      "1158: [discriminator loss: 0.181890, acc: 0.773438] [adversarial loss: 0.786728, acc: 0.031250]\n",
      "1159: [discriminator loss: 0.164321, acc: 0.773438] [adversarial loss: 0.519045, acc: 0.156250]\n",
      "1160: [discriminator loss: 0.147205, acc: 0.851562] [adversarial loss: 0.540457, acc: 0.109375]\n",
      "1161: [discriminator loss: 0.131723, acc: 0.859375] [adversarial loss: 0.563964, acc: 0.078125]\n",
      "1162: [discriminator loss: 0.136645, acc: 0.796875] [adversarial loss: 0.542883, acc: 0.171875]\n",
      "1163: [discriminator loss: 0.142420, acc: 0.828125] [adversarial loss: 0.403278, acc: 0.390625]\n",
      "1164: [discriminator loss: 0.140666, acc: 0.835938] [adversarial loss: 0.628529, acc: 0.078125]\n",
      "1165: [discriminator loss: 0.137039, acc: 0.812500] [adversarial loss: 0.571193, acc: 0.078125]\n",
      "1166: [discriminator loss: 0.168923, acc: 0.750000] [adversarial loss: 0.540283, acc: 0.156250]\n",
      "1167: [discriminator loss: 0.154470, acc: 0.765625] [adversarial loss: 0.673919, acc: 0.093750]\n",
      "1168: [discriminator loss: 0.155308, acc: 0.757812] [adversarial loss: 0.431727, acc: 0.265625]\n",
      "1169: [discriminator loss: 0.133260, acc: 0.820312] [adversarial loss: 0.528937, acc: 0.125000]\n",
      "1170: [discriminator loss: 0.190098, acc: 0.734375] [adversarial loss: 0.551208, acc: 0.156250]\n",
      "1171: [discriminator loss: 0.144043, acc: 0.828125] [adversarial loss: 0.605891, acc: 0.031250]\n",
      "1172: [discriminator loss: 0.149454, acc: 0.789062] [adversarial loss: 0.463499, acc: 0.234375]\n",
      "1173: [discriminator loss: 0.129011, acc: 0.851562] [adversarial loss: 0.691702, acc: 0.062500]\n",
      "1174: [discriminator loss: 0.168401, acc: 0.726562] [adversarial loss: 0.391064, acc: 0.296875]\n",
      "1175: [discriminator loss: 0.178038, acc: 0.750000] [adversarial loss: 0.746354, acc: 0.015625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176: [discriminator loss: 0.180675, acc: 0.726562] [adversarial loss: 0.290610, acc: 0.515625]\n",
      "1177: [discriminator loss: 0.168404, acc: 0.757812] [adversarial loss: 0.781406, acc: 0.031250]\n",
      "1178: [discriminator loss: 0.144443, acc: 0.773438] [adversarial loss: 0.405604, acc: 0.296875]\n",
      "1179: [discriminator loss: 0.143358, acc: 0.789062] [adversarial loss: 0.747754, acc: 0.031250]\n",
      "1180: [discriminator loss: 0.176177, acc: 0.742188] [adversarial loss: 0.420593, acc: 0.218750]\n",
      "1181: [discriminator loss: 0.133153, acc: 0.859375] [adversarial loss: 0.652430, acc: 0.062500]\n",
      "1182: [discriminator loss: 0.147632, acc: 0.773438] [adversarial loss: 0.433078, acc: 0.203125]\n",
      "1183: [discriminator loss: 0.148637, acc: 0.820312] [adversarial loss: 0.679725, acc: 0.031250]\n",
      "1184: [discriminator loss: 0.148856, acc: 0.820312] [adversarial loss: 0.446467, acc: 0.218750]\n",
      "1185: [discriminator loss: 0.140754, acc: 0.835938] [adversarial loss: 0.619632, acc: 0.046875]\n",
      "1186: [discriminator loss: 0.125652, acc: 0.828125] [adversarial loss: 0.520413, acc: 0.140625]\n",
      "1187: [discriminator loss: 0.147669, acc: 0.835938] [adversarial loss: 0.628530, acc: 0.062500]\n",
      "1188: [discriminator loss: 0.180150, acc: 0.734375] [adversarial loss: 0.549721, acc: 0.218750]\n",
      "1189: [discriminator loss: 0.137269, acc: 0.820312] [adversarial loss: 0.471598, acc: 0.187500]\n",
      "1190: [discriminator loss: 0.162734, acc: 0.750000] [adversarial loss: 0.583360, acc: 0.062500]\n",
      "1191: [discriminator loss: 0.140520, acc: 0.828125] [adversarial loss: 0.594136, acc: 0.078125]\n",
      "1192: [discriminator loss: 0.139029, acc: 0.789062] [adversarial loss: 0.600881, acc: 0.078125]\n",
      "1193: [discriminator loss: 0.130373, acc: 0.843750] [adversarial loss: 0.445597, acc: 0.203125]\n",
      "1194: [discriminator loss: 0.153517, acc: 0.796875] [adversarial loss: 0.807264, acc: 0.062500]\n",
      "1195: [discriminator loss: 0.176340, acc: 0.734375] [adversarial loss: 0.300103, acc: 0.453125]\n",
      "1196: [discriminator loss: 0.179600, acc: 0.750000] [adversarial loss: 0.807867, acc: 0.031250]\n",
      "1197: [discriminator loss: 0.178997, acc: 0.742188] [adversarial loss: 0.367440, acc: 0.359375]\n",
      "1198: [discriminator loss: 0.165230, acc: 0.804688] [adversarial loss: 0.772217, acc: 0.046875]\n",
      "1199: [discriminator loss: 0.168853, acc: 0.757812] [adversarial loss: 0.348729, acc: 0.375000]\n",
      "1200: [discriminator loss: 0.159043, acc: 0.757812] [adversarial loss: 0.746030, acc: 0.062500]\n",
      "1201: [discriminator loss: 0.147757, acc: 0.796875] [adversarial loss: 0.493512, acc: 0.218750]\n",
      "1202: [discriminator loss: 0.174844, acc: 0.796875] [adversarial loss: 0.868178, acc: 0.015625]\n",
      "1203: [discriminator loss: 0.190999, acc: 0.687500] [adversarial loss: 0.450492, acc: 0.203125]\n",
      "1204: [discriminator loss: 0.152259, acc: 0.734375] [adversarial loss: 0.538774, acc: 0.140625]\n",
      "1205: [discriminator loss: 0.165783, acc: 0.742188] [adversarial loss: 0.396027, acc: 0.296875]\n",
      "1206: [discriminator loss: 0.141923, acc: 0.812500] [adversarial loss: 0.609970, acc: 0.062500]\n",
      "1207: [discriminator loss: 0.159470, acc: 0.773438] [adversarial loss: 0.410425, acc: 0.312500]\n",
      "1208: [discriminator loss: 0.152188, acc: 0.820312] [adversarial loss: 0.669817, acc: 0.078125]\n",
      "1209: [discriminator loss: 0.138982, acc: 0.796875] [adversarial loss: 0.450661, acc: 0.203125]\n",
      "1210: [discriminator loss: 0.193533, acc: 0.710938] [adversarial loss: 0.697712, acc: 0.078125]\n",
      "1211: [discriminator loss: 0.157730, acc: 0.820312] [adversarial loss: 0.370902, acc: 0.359375]\n",
      "1212: [discriminator loss: 0.152449, acc: 0.796875] [adversarial loss: 0.661070, acc: 0.062500]\n",
      "1213: [discriminator loss: 0.162263, acc: 0.757812] [adversarial loss: 0.408660, acc: 0.171875]\n",
      "1214: [discriminator loss: 0.180640, acc: 0.773438] [adversarial loss: 0.525322, acc: 0.125000]\n",
      "1215: [discriminator loss: 0.132798, acc: 0.812500] [adversarial loss: 0.488515, acc: 0.140625]\n",
      "1216: [discriminator loss: 0.170925, acc: 0.726562] [adversarial loss: 0.400562, acc: 0.343750]\n",
      "1217: [discriminator loss: 0.121594, acc: 0.882812] [adversarial loss: 0.606967, acc: 0.078125]\n",
      "1218: [discriminator loss: 0.135405, acc: 0.828125] [adversarial loss: 0.443599, acc: 0.281250]\n",
      "1219: [discriminator loss: 0.141970, acc: 0.820312] [adversarial loss: 0.614813, acc: 0.125000]\n",
      "1220: [discriminator loss: 0.163886, acc: 0.718750] [adversarial loss: 0.376507, acc: 0.296875]\n",
      "1221: [discriminator loss: 0.163295, acc: 0.804688] [adversarial loss: 0.811366, acc: 0.000000]\n",
      "1222: [discriminator loss: 0.165153, acc: 0.781250] [adversarial loss: 0.344848, acc: 0.437500]\n",
      "1223: [discriminator loss: 0.167523, acc: 0.750000] [adversarial loss: 0.705151, acc: 0.031250]\n",
      "1224: [discriminator loss: 0.177416, acc: 0.726562] [adversarial loss: 0.472202, acc: 0.234375]\n",
      "1225: [discriminator loss: 0.153743, acc: 0.734375] [adversarial loss: 0.713722, acc: 0.046875]\n",
      "1226: [discriminator loss: 0.147944, acc: 0.789062] [adversarial loss: 0.374387, acc: 0.234375]\n",
      "1227: [discriminator loss: 0.174424, acc: 0.781250] [adversarial loss: 0.583133, acc: 0.109375]\n",
      "1228: [discriminator loss: 0.131288, acc: 0.843750] [adversarial loss: 0.477513, acc: 0.203125]\n",
      "1229: [discriminator loss: 0.151355, acc: 0.789062] [adversarial loss: 0.521506, acc: 0.156250]\n",
      "1230: [discriminator loss: 0.112785, acc: 0.843750] [adversarial loss: 0.534692, acc: 0.125000]\n",
      "1231: [discriminator loss: 0.153499, acc: 0.765625] [adversarial loss: 0.524611, acc: 0.187500]\n",
      "1232: [discriminator loss: 0.134836, acc: 0.828125] [adversarial loss: 0.531487, acc: 0.250000]\n",
      "1233: [discriminator loss: 0.191495, acc: 0.718750] [adversarial loss: 0.483277, acc: 0.187500]\n",
      "1234: [discriminator loss: 0.146168, acc: 0.828125] [adversarial loss: 0.674945, acc: 0.015625]\n",
      "1235: [discriminator loss: 0.144595, acc: 0.796875] [adversarial loss: 0.399157, acc: 0.312500]\n",
      "1236: [discriminator loss: 0.152153, acc: 0.812500] [adversarial loss: 0.771276, acc: 0.031250]\n",
      "1237: [discriminator loss: 0.146503, acc: 0.796875] [adversarial loss: 0.408070, acc: 0.281250]\n",
      "1238: [discriminator loss: 0.179293, acc: 0.726562] [adversarial loss: 0.828209, acc: 0.062500]\n",
      "1239: [discriminator loss: 0.161407, acc: 0.750000] [adversarial loss: 0.357901, acc: 0.328125]\n",
      "1240: [discriminator loss: 0.176567, acc: 0.750000] [adversarial loss: 0.615162, acc: 0.093750]\n",
      "1241: [discriminator loss: 0.174123, acc: 0.687500] [adversarial loss: 0.384721, acc: 0.265625]\n",
      "1242: [discriminator loss: 0.147363, acc: 0.843750] [adversarial loss: 0.670434, acc: 0.062500]\n",
      "1243: [discriminator loss: 0.159760, acc: 0.773438] [adversarial loss: 0.369395, acc: 0.406250]\n",
      "1244: [discriminator loss: 0.146989, acc: 0.773438] [adversarial loss: 0.580290, acc: 0.125000]\n",
      "1245: [discriminator loss: 0.120142, acc: 0.851562] [adversarial loss: 0.525420, acc: 0.125000]\n",
      "1246: [discriminator loss: 0.150884, acc: 0.812500] [adversarial loss: 0.697330, acc: 0.093750]\n",
      "1247: [discriminator loss: 0.181877, acc: 0.734375] [adversarial loss: 0.406859, acc: 0.218750]\n",
      "1248: [discriminator loss: 0.151114, acc: 0.796875] [adversarial loss: 0.624300, acc: 0.031250]\n",
      "1249: [discriminator loss: 0.137843, acc: 0.828125] [adversarial loss: 0.553099, acc: 0.187500]\n",
      "1250: [discriminator loss: 0.146237, acc: 0.804688] [adversarial loss: 0.482165, acc: 0.171875]\n",
      "1251: [discriminator loss: 0.149588, acc: 0.828125] [adversarial loss: 0.493335, acc: 0.171875]\n",
      "1252: [discriminator loss: 0.149714, acc: 0.796875] [adversarial loss: 0.607757, acc: 0.156250]\n",
      "1253: [discriminator loss: 0.136345, acc: 0.812500] [adversarial loss: 0.474597, acc: 0.156250]\n",
      "1254: [discriminator loss: 0.142249, acc: 0.835938] [adversarial loss: 0.643099, acc: 0.109375]\n",
      "1255: [discriminator loss: 0.158437, acc: 0.773438] [adversarial loss: 0.331373, acc: 0.437500]\n",
      "1256: [discriminator loss: 0.181969, acc: 0.718750] [adversarial loss: 0.882191, acc: 0.000000]\n",
      "1257: [discriminator loss: 0.168019, acc: 0.765625] [adversarial loss: 0.360353, acc: 0.437500]\n",
      "1258: [discriminator loss: 0.174892, acc: 0.742188] [adversarial loss: 0.730360, acc: 0.062500]\n",
      "1259: [discriminator loss: 0.160938, acc: 0.726562] [adversarial loss: 0.412815, acc: 0.281250]\n",
      "1260: [discriminator loss: 0.145817, acc: 0.828125] [adversarial loss: 0.621324, acc: 0.062500]\n",
      "1261: [discriminator loss: 0.153442, acc: 0.781250] [adversarial loss: 0.421762, acc: 0.234375]\n",
      "1262: [discriminator loss: 0.147819, acc: 0.820312] [adversarial loss: 0.750376, acc: 0.015625]\n",
      "1263: [discriminator loss: 0.162574, acc: 0.742188] [adversarial loss: 0.394046, acc: 0.250000]\n",
      "1264: [discriminator loss: 0.148948, acc: 0.781250] [adversarial loss: 0.682275, acc: 0.062500]\n",
      "1265: [discriminator loss: 0.164306, acc: 0.750000] [adversarial loss: 0.487878, acc: 0.234375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266: [discriminator loss: 0.167664, acc: 0.773438] [adversarial loss: 0.518302, acc: 0.187500]\n",
      "1267: [discriminator loss: 0.127026, acc: 0.843750] [adversarial loss: 0.590228, acc: 0.109375]\n",
      "1268: [discriminator loss: 0.131195, acc: 0.828125] [adversarial loss: 0.483095, acc: 0.234375]\n",
      "1269: [discriminator loss: 0.122675, acc: 0.859375] [adversarial loss: 0.597090, acc: 0.171875]\n",
      "1270: [discriminator loss: 0.128335, acc: 0.828125] [adversarial loss: 0.456190, acc: 0.187500]\n",
      "1271: [discriminator loss: 0.156644, acc: 0.789062] [adversarial loss: 0.484547, acc: 0.187500]\n",
      "1272: [discriminator loss: 0.157467, acc: 0.781250] [adversarial loss: 0.515113, acc: 0.171875]\n",
      "1273: [discriminator loss: 0.126131, acc: 0.828125] [adversarial loss: 0.532350, acc: 0.171875]\n",
      "1274: [discriminator loss: 0.157236, acc: 0.765625] [adversarial loss: 0.682319, acc: 0.046875]\n",
      "1275: [discriminator loss: 0.159935, acc: 0.765625] [adversarial loss: 0.355039, acc: 0.375000]\n",
      "1276: [discriminator loss: 0.178473, acc: 0.742188] [adversarial loss: 0.836837, acc: 0.015625]\n",
      "1277: [discriminator loss: 0.190986, acc: 0.703125] [adversarial loss: 0.364891, acc: 0.328125]\n",
      "1278: [discriminator loss: 0.178642, acc: 0.703125] [adversarial loss: 0.904275, acc: 0.046875]\n",
      "1279: [discriminator loss: 0.200009, acc: 0.687500] [adversarial loss: 0.397431, acc: 0.312500]\n",
      "1280: [discriminator loss: 0.170494, acc: 0.742188] [adversarial loss: 0.761904, acc: 0.046875]\n",
      "1281: [discriminator loss: 0.132769, acc: 0.828125] [adversarial loss: 0.438299, acc: 0.203125]\n",
      "1282: [discriminator loss: 0.156558, acc: 0.796875] [adversarial loss: 0.574430, acc: 0.078125]\n",
      "1283: [discriminator loss: 0.137894, acc: 0.789062] [adversarial loss: 0.461994, acc: 0.187500]\n",
      "1284: [discriminator loss: 0.140855, acc: 0.820312] [adversarial loss: 0.673634, acc: 0.062500]\n",
      "1285: [discriminator loss: 0.158527, acc: 0.820312] [adversarial loss: 0.521795, acc: 0.125000]\n",
      "1286: [discriminator loss: 0.129428, acc: 0.828125] [adversarial loss: 0.540901, acc: 0.140625]\n",
      "1287: [discriminator loss: 0.144946, acc: 0.804688] [adversarial loss: 0.615344, acc: 0.062500]\n",
      "1288: [discriminator loss: 0.152331, acc: 0.765625] [adversarial loss: 0.494083, acc: 0.187500]\n",
      "1289: [discriminator loss: 0.140754, acc: 0.835938] [adversarial loss: 0.683533, acc: 0.046875]\n",
      "1290: [discriminator loss: 0.151139, acc: 0.781250] [adversarial loss: 0.359788, acc: 0.421875]\n",
      "1291: [discriminator loss: 0.146873, acc: 0.820312] [adversarial loss: 0.609253, acc: 0.109375]\n",
      "1292: [discriminator loss: 0.142374, acc: 0.789062] [adversarial loss: 0.389363, acc: 0.312500]\n",
      "1293: [discriminator loss: 0.137528, acc: 0.804688] [adversarial loss: 0.679477, acc: 0.093750]\n",
      "1294: [discriminator loss: 0.144481, acc: 0.773438] [adversarial loss: 0.567404, acc: 0.140625]\n",
      "1295: [discriminator loss: 0.150787, acc: 0.835938] [adversarial loss: 0.427214, acc: 0.250000]\n",
      "1296: [discriminator loss: 0.149018, acc: 0.812500] [adversarial loss: 0.733780, acc: 0.031250]\n",
      "1297: [discriminator loss: 0.148062, acc: 0.789062] [adversarial loss: 0.477615, acc: 0.250000]\n",
      "1298: [discriminator loss: 0.124642, acc: 0.882812] [adversarial loss: 0.748474, acc: 0.046875]\n",
      "1299: [discriminator loss: 0.159372, acc: 0.765625] [adversarial loss: 0.436113, acc: 0.296875]\n",
      "1300: [discriminator loss: 0.162030, acc: 0.757812] [adversarial loss: 0.566332, acc: 0.187500]\n",
      "1301: [discriminator loss: 0.141282, acc: 0.820312] [adversarial loss: 0.513704, acc: 0.156250]\n",
      "1302: [discriminator loss: 0.126432, acc: 0.851562] [adversarial loss: 0.601050, acc: 0.062500]\n",
      "1303: [discriminator loss: 0.152130, acc: 0.757812] [adversarial loss: 0.424042, acc: 0.281250]\n",
      "1304: [discriminator loss: 0.173333, acc: 0.757812] [adversarial loss: 0.564211, acc: 0.203125]\n",
      "1305: [discriminator loss: 0.155372, acc: 0.789062] [adversarial loss: 0.426326, acc: 0.203125]\n",
      "1306: [discriminator loss: 0.154993, acc: 0.796875] [adversarial loss: 0.743190, acc: 0.078125]\n",
      "1307: [discriminator loss: 0.172507, acc: 0.757812] [adversarial loss: 0.295957, acc: 0.500000]\n",
      "1308: [discriminator loss: 0.169203, acc: 0.757812] [adversarial loss: 0.837777, acc: 0.046875]\n",
      "1309: [discriminator loss: 0.167553, acc: 0.742188] [adversarial loss: 0.359174, acc: 0.343750]\n",
      "1310: [discriminator loss: 0.173078, acc: 0.734375] [adversarial loss: 0.729674, acc: 0.046875]\n",
      "1311: [discriminator loss: 0.150715, acc: 0.765625] [adversarial loss: 0.428686, acc: 0.171875]\n",
      "1312: [discriminator loss: 0.172847, acc: 0.726562] [adversarial loss: 0.634363, acc: 0.109375]\n",
      "1313: [discriminator loss: 0.183745, acc: 0.734375] [adversarial loss: 0.489030, acc: 0.187500]\n",
      "1314: [discriminator loss: 0.140114, acc: 0.820312] [adversarial loss: 0.594139, acc: 0.156250]\n",
      "1315: [discriminator loss: 0.142067, acc: 0.820312] [adversarial loss: 0.483977, acc: 0.234375]\n",
      "1316: [discriminator loss: 0.144131, acc: 0.828125] [adversarial loss: 0.593779, acc: 0.125000]\n",
      "1317: [discriminator loss: 0.137515, acc: 0.804688] [adversarial loss: 0.563033, acc: 0.093750]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-566a5db89054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversarial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/project/Advanced-Deep-Learning-With-Keras/lib/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, x_train, params)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# train discriminator network, log the loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%d: [discriminator loss: %f, acc: %f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train discriminator and adversarial networks\n",
    "models = (generator, discriminator, adversarial)\n",
    "params = (batch_size, latent_size, train_steps, model_name)\n",
    "gan.train(models, x_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 158.4x158.4 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = load_model(\"lsgan_mnist.h5\")\n",
    "gan.test_generator(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
